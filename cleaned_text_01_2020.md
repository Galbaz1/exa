
## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/29/what-is-our-meaning-in-life-in-a-world-of-technology/
### Query Relevance Score: 0.12224207818508148
### Highlights: None

The informal TechCrunch book club is now venturing into the short story “Exhalation,” the second piece in Ted Chiang’s eponymous collection. Today’s story gets at the meaning of existence, climate change, community and connection all within a beautifully intricate story that runs for just a few handfuls of pages. I was hooked, and so let’s talk about some of the messages Chiang wants to send as part of the piece. Some quick notes: Want to join the conversation? Feel free to email me your thoughts at bookclub@techcrunch.com or join some of the discussions on Reddit or Twitter (hashtag: #TCBookClub) Follow these informal book club articles here: https://techcrunch.com/book-review/. That page also has a built-in RSS feed for posts exclusively in the Book Review category, which is very low volume. Feel free to add your comments in our TechCrunch comments section below this post. Thoughts on “Exhalation” Chiang has constructed a magnificent story around the most basic and forgettable of substances: air. He starts the story with what otherwise appears to be a normal day in the life of an everyday human, but within a few paragraphs, we learn that the narrator is “going to the filling stations” and it slowly dawns on us that the narrator — and all the people that populate this imaginative world — are actually some form of cybernetic beings, dependent on a mechanical supply of air for their machined bodies. We learn that these filling stations, where people pick up their air supply, aren’t just refueling utilities, but are key community outposts where connections are formed between people. “For the filling stations are the primary venue for social conversation, the places from which we draw emotional sustenance as well as physical.” But that’s not all, Chiang writes. “… there is camaraderie derived from the awareness that all our air comes from the same source…” As we learn as the story progresses, air isn’t just present in this universe — it is fundamentally the connective substance not only between every individual, but also the past and the future. Memories held in the brains of these individuals aren’t inscribed, but are rather reconfigured as air passes through them. Therefore, what is memorable — what is most visible — is ultimately a function of what is not even seen. The narrator describes this discovery as he investigates his own brain in an experiment: Watching the oscillations of these flakes of gold, I saw that air does not, as we had always assumed, simply provide power to the engine that realizes our thoughts. Air is in fact the very medium of our thoughts. All that we are is a pattern of air flow. What’s incredible about this story is that Chiang pushes this metaphor another layer deeper. The narrator learns that the world relies on the pressure difference between the air in the atmosphere and the air in each individual’s body, and that this difference is decreasing. Suddenly, the fate of the entire universe has become clear: There may well be air everywhere, but it’s the differential that matters, and that differential is slowly receding with every breath, every twitch of a limb and stray thought. Equilibrium — and therefore death — is just around the corner. Gloriously, Chiang describes the dawn of time: The universe began as an enormous breath being held. Who knows why, but whatever the reason, I am glad that it did, because I owe my existence to that fact. All my desires and ruminations are no more and no less than eddy currents generated by the gradual exhalation of our universe. And until this great exhalation is finished, my thoughts live on. This is an ambitious leap and one that springs beautifully from the page. We have gone from air as individual sustenance, to air as community resource and connective tissue, to air as the very meaning of existence, tied into a fate where we already know how the final chapter will be written. Here is the substance we never think about, and instead of being nothing it is actually everything we care about. There is a parallel here of course to our own world. In much the way the everyday actions of the individuals in this short story deplete the pressure difference of their world and ultimately make it uninhabitable, there is clearly a connection to our own present crisis regarding climate change. How should we handle the fatalism of those climate trendlines that show Earth eventually dying off sometime in the future? The story doesn’t try to minimize that fatalism. In fact, it actively diminishes the idea that there are technical solutions to these problems. Our narrator describes a sect known as the “Reversalists,” who attempt to build a machine that can increase the difference in air pressure in the universe. But our narrator isn’t optimistic, and essentially argues that such a machine is impossible to design. Instead, the story exhorts us to revel in the limited time we have in this universe, even knowing that the world is going to come to an inevitable end. “Because even if a universe’s life span is calculable, the variety of life that is generated within it is not.” Rather than spending our limited time trying to push back the end (of the universe or of our own demise), we should instead ignore that fatal ending and focus on the present, and the wonders that we get to experience while the world is alive for us. I can go on and on about air here, and indeed, multiple re-readings of this chapter have revealed new connections and symbols that are absolutely fascinating. But I want to move on to two other points that I think this short story wants to tell. In the story, our narrator is an anatomist, who learns about a strange set of facts — that clocks appear to be changing speed in multiple districts in this universe. They learn about these facts, but unlike anyone else, they seem willing to ask more fundamental and deeper questions about why basic mechanics of the universe aren’t what they seem: Most people suspected fraud, a practical joke perpetrated by mischief-makers. I had a different suspicion, a darker one that I dared not voice, but it decided my course of action; I would proceed with my experiment. Our narrator explains that there is a reigning theory about the workings of the brain called the inscription hypothesis, which they reject. By the end of the story though, we see how our narrator’s experiment of opening their own brain and investigating its workings eventually overturned that hypothesis. It’s not only a commentary on the scientific method, but I also feel that there is a point here about asking even the hardest questions about the data that we are seeing in our universe. We talk about this all the time in the startup world, but here we have in clear relief a person who didn’t just accept the prevailing theory of how something worked, or ignored the facts and data from their universe, or avoided approaching the hardest questions they stumbled upon. Instead, they confronted them, and also did so individually, without the consent or approval of others. That’s a reminder that sometimes, when we are on the frontiers of science, that the hardest questions sometimes can’t be answered in collaboration with others — that the air that connects us breaks down here. The other symbol I loved here is around the “experiment” itself. Our narrator builds a machine that allows them to dissect their own brain, and in the process allows them to see the true meaning of the universe. Chiang spends a sizable part of the story building up the dissection, going through with it and discussing its implications, and it isn’t hard to see why. The brain dissection is a beautiful metaphor for literally “opening our minds” to new experiences and ideas. Our narrator carefully prepares to open their mind, splaying their brain out in a painstaking and careful order to understand its inner workings. As they do this though, they discover who they really are, and also the fate of the universe along the way. It’s a gorgeous symbol, and like so much of this story, a layered opinion about what it means to be an individual and how we relate to each other. As Chiang closes out, “Contemplate the marvel that is existence, and rejoice that you are able to do so. I feel I have the right to tell you this because, as I am inscribing these words, I am doing the same.” Some questions for “What’s Expected of Us” Next week, we will read the ultra-short story (four pages!), the third part of “Exhalation” the collection. It’s an interesting meditation on free will versus destiny, and asks a lot of questions in a taut story. Have comments on what you read? Send them to me at bookclub@techcrunch.com

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/17/deep-tech-vcs-on-what-they-view-as-some-of-the-most-impactful-young-startups-right-now/
### Query Relevance Score: 0.12063054740428925
### Highlights: None

During this week’s Democratic debate, there was a lot of talk, unsurprisingly, about ensuring the future of this country’s children and grandchildren. Climate change was of particular interest to billionaire Tom Steyer, who said repeatedly that addressing it would be his top priority were he elected U.S. president. As it happens, earlier the same day, we’d spent time on the phone with two venture capitalists who think of almost nothing else every day. The reason: they both invest in so-called deep tech, and they meet routinely with startups whose central focus is on making the world habitable for generations of people to come — as well as trying to produce outsize financial returns, of course. The two VCs with whom we talked know each other well. Siraj Khaliq is a partner at the global venture firm Atomico, where he tries to find world-changing startups that are enabled by machine learning, AI, and computer vision. He has strong experience in the area, having cofounded The Climate Corporation back in 2006, a company that helps farmers optimize crop yield and that was acquired by Monsanto in 2013 for roughly $1 billion. Seth Bannon is meanwhile a founding partner of Fifty Years, a nearly five-year-old, San Francisco-based seed-stage fund whose stated ambition is backing founders who want to solve the world’s biggest problems. The investors’ interests overlap so much that Khaliq is also one of Fifty Years’s investors. From both, we wanted to know which companies or trends are capturing their imagination and, in some cases, their investment dollars. Following are excerpts from our extended conversation earlier this week. (We thought it was interesting; hopefully you will, too.) TC: Seth, how would you describe what you’re looking to fund at your firm? SB: There’s a Winston Churchill essay [penned nearly 100 years ago] called “Fifty Years Hence” that describes what we do. He predicts genomic engineering, synthetic biology, growing meat without animals, nuclear power, satellite telephony. Churchill also notes that because tech changes so quickly that it’s important that technologists take a principled approach to their work. [Inspired by him] we’re backing founders who can make a ton of money while doing good and focusing on health, disease, the climate crisis . . . TC: What does that mean exactly? Are you investing in software? SB: We’re not so enthusiastic about pure software because it’s been so abstracted away that it’s become a commodity. High school students can now build an app, which is great, but it also means that competitive pressures are very high. There are a thousand funds focused on software seed investing. Fortunately, you can now launch a synthetic biology startup with seed funding, and that wasn’t possible 10 years ago. There are a lot of infrastructural advancements happening that makes [deep tech investing even with smaller checks] interesting. TC: Siraj, you also invest exclusively on frontier, or deep tech, at Atomico. What’s your approach to funding startups? SK: We do Series A [deals] onward and don’t do seed stage. We primarily focus on Europe. But there’s lot of common thinking between us and Seth. As a fund, we’re looking for big problems that change the world, sometimes at companies that won’t necessarily be big in five years but if you look out 10 years could be necessary for humanity. So we’re trying to anticipate all of these big trends and focus on three or four theses a year and talk as much as we can with academics and other experts to understand what’s going on. Founders then know we have an informed view. Last year, we focused on synthetic biology, which is a becoming so broad a category that it’s time to start subdividing it. We were also doing AI-based drug discovery and quantum computing and we started to spend some time on energy as well. We also [continued an earlier focus on ] the future of manufacturing and industry. We see a number of trends that make [the latter] attractive, especially in Europe where manufacturing hasn’t yet been digitized. TC: Seth, you mentioned synthetic biology infrastructure. Can you elaborate on what you’re seeing that’s interesting on this front? SB: You’ve maybe heard of directed evolution, technology that allows biologists to use the power of evolution to get microbes or other biological machines to do what they want them to do that would have been impossible before. [Editor’s note: here, Bannon talks a bit about Frances Arnold, the Nobel Prize-winning chemist who was awarded the honor in 2018 for developing the technique.] So we’re excited to back [related] startups. One, Solugen, enzymatically makes industrial chemicals [by combining genetically modified enzymes with organic compounds, like plant sugars]. Hydrogen peroxide is a $6 billion dollar industry, and it’s currently made through a petroleum-based process in seven-football-field-long production plants that sometimes explode and kill people. TC: Is this then akin to Zymergen, which develops molecules in order to create unique specialty materials? SB: Zymergen mainly works as a kind of consultant to help companies engineer strains that they want. Solugen is a vertically integrated chemicals company, so it [creates its formulations], then sells directly into industry. TC: How does this relate to new architectures? SB: The way to think about it is that there’s a bunch of application-level companies, but as synthetic biology companies start to take off, there’s a bunch of emerging infrastructure layer companies. One of these is Ansa Biotechnologies, which has a fully enzymatic process for writing DNA. Like Twist, which went public, they make DNA to sell to customers in the biotech industry. But whereas Twist is using a chemical process to make DNA, Ansa’s approach is fully enzymatic. [Editor’s note: More on the competition in this emerging space here.] Also, if you look at plant-based alternatives to meat, they’re more sustainable but also far more expensive than traditional beef. Why is that? Well plant-based chicken is more expensive because the processing infrastructure being used is more than 10 years behind real chicken processing, where you’ll see robot arms that cut up chicken so efficiently that it looks like a Tesla factory. [Alternative meat] companies are basically using these extruders built in the ’70s because the industry has been so small, and that’s because there’s been a lot of skepticism from the investment community in these companies. Or there was. The performance of Beyond Meat’s IPO ended it. Now there’s a rush of founders and dollars into that space, and whenever you have a space where the core infrastructure has been neglected, there’s opportunity. A former mechanical engineer with Boeing has started a company, Rebellyous Foods, to basically build the AWS for the plant-based food industry, for example. She’s using [the machines she’s building] to sell plant-based chicken nuggets, [but that’s the longer-term plan]. TC: Siraj, you say last year you started to spend time on energy. What’s interesting to you as it relates to energy? SK: There’s been some improvement in how we capture emissions, but [carbon emissions] are still very deleterious to our health and the planet’s health, and there are a few areas to think about [to address the problem]. Helping people measure and control their consumption is one approach, but also we think about how to produce new energy, which is a shift we [meaning mankind] need to undertake. The challenge [in making that shift] is often [capital expenditures]. It’s hard for venture investors to back companies that are [building nuclear reactors], which makes government grants the best choice for early innovation oftentimes. There is one company, Seaborg, that has figured out a clever reactor. It’s not a portfolio company but it’s [compelling]. SB: We also really like what Seaborg is doing. These [fourth generation] nuclear companies have a whole host of approaches that allow for smaller, safer reactors that you wouldn’t mind having in your backyard. But Siraj put his finger on it: as an early-stage deep tech investor, we have to consider the capital plan of a company, and if it needs to raise billions of dollars, early investors will get really diluted, so early-stage venture just isn’t the best fit. TC: There are other areas you like, though, because costs have fallen so much. SB: Yes. Satellite telephony used to be one of those areas. Some of the satellites in space right now cost $350 million [to launch] and took three to four years to build, which would be really hard for any early-stage investor to fund. But now, a new generation of companies is building satellites for one-tenth of the cost in months, not years. That’s a game changer. They can iterate faster. They can build a better product. They don’t have to raise equity to build and launch either; they can raise from a debt financier [from whom they can] borrow money and pay it back over time. That model isn’t available to a company like Uber or Lyft, because those companies can’t say, ‘X is going to cost us Y dollars and it will pay back Z over time.’ TC: What of concerns that all these cheap satellites are going to clog up the sky pretty quickly? SB: It’s a real concern. Most [of today’s satellites] are low earth satellites, and the closer to the earth they are, the brighter they are; they reflect the sun more, the more satellites we’re seeing instead of stars. I do think it’s incumbent on all of these companies to think about how they are contributing to the future of humanity. But when you connect the unconnected, educational outcomes improve, health improves, inequality decreases, and the stability of governments improves, so maybe the developed world needs to sacrifice a bit. I think that’s a reasonable tradeoff. If on the other hand, we’re putting up satellites to help people buy more crap . . . TC: It’s like the argument for self-driving cars in a way. Life becomes more efficient, but they’ll require far more energy generation, for example. There are always second-order consequences. SK: But think of how many people are killed in driving accidents, versus terrorist attacks. Humans have many great qualities, but being able to drive a lethal machine consistently isn’t one of them. So when we take that into perspective, it’s really important that we build autonomous vehicles. You [voice] a legitimate concern, and often when there are step changes, there are discontinuities along the way that lead to side effects that aren’t great. That comes down to several things. First, infrastructure will have to keep up. We’ll also have to create regulations that don’t lead to the worst outcomes. One our investments, Lilium in Munich, has built an entirely electric air taxi service that’s built on vertical takeoff. It’s nimble. It’s quiet enough to operate in city environments. On roads, cars are constrained by 2D terrain and buildings, but [in the air] if you can do dynamic air traffic control, it opens up far much efficient transport. If you can get from downtown London to Heathrow [airport] in five minutes versus 50 minutes in a Tesla? That’s far more energy efficient.

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/03/adobe-cto-says-ai-will-democratize-creative-tools/
### Query Relevance Score: 0.11661754548549652
### Highlights: None

Adobe CTO Abhay Parasnis sees a shift happening. A shift in how people share content and who wants to use creative tools. A shift in how users expect these tools to work — especially how much time they take to learn and how quickly they get things done. I spoke with Parasnis in December to learn more about where Adobe’s products are going and how they’ll get there — even if it means rethinking how it all works today. “What could we build that makes today’s Photoshop, or today’s Premiere, or today’s Illustrator look irrelevant five years from now?” he asked. In many cases, that means a lot more artificial intelligence; AI to flatten the learning curve, allowing the user to command apps like Photoshop not only by digging through menus, but by literally telling Photoshop what they want done (as in, with their voice). AI to better understand what the user is doing, helping to eliminate mundane or repetitive tasks. AI to, as Parasnis puts it, “democratize” Adobe’s products. We’ve seen some hints of this already. Back in November, Adobe announced Photoshop Camera, a free iOS/Android app that repurposes the Photoshop engine into a lightweight but AI-heavy interface that allows for fancy filters and complex effects with minimal effort or learning required of the user. I see it as Adobe’s way of acknowledging (flexing on?) the Snapchats and Instas of the world, saying “oh, don’t worry, we can do that too.” But the efforts to let AI do more and more of the heavy lifting won’t stop with free apps. “We think AI has the potential to dramatically reduce the learning curve and make people productive — not at the edges, but 10x, 100x improvement in productivity,” said Parasnis. “The last decade or two decades of creativity were limited to professionals, people who really were high-end animators, high-end designers… why isn’t it for every student or every consumer that has a story to tell? They shouldn’t be locked out of these powerful tools only because they’re either costly, or they are more complex to learn. We can democratize that by simplifying the workflow.”

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/26/technology-is-anthropology/
### Query Relevance Score: 0.11261038482189178
### Highlights: None

The interesting thing about the technology business is that, most of the time, it’s not the technology that matters. What matters is how people react to it, and what new social norms they form. This is especially true in today’s era, well past the midpoint of the deployment age of smartphones and the internet. People — smart, thoughtful people, with relevant backgrounds and domain knowledge — thought that Airbnb and Uber were doomed to failure, because obviously no one would want to stay in a stranger’s home or ride in a stranger’s car. People thought the iPhone would flop, because users would “detest the touch screen interface.” People thought enterprise software-as-a-service would never fly, because executives would insist on keeping servers in-house at all costs. These people were so, so, so wrong; but note that they weren’t wrong about the technology. (Nobody really argued about the technology.) Instead they were dead wrong about other people, and how their own society and culture would respond to this new stimulus. They were anthropologically incorrect. This, of course, is why every major VC firm, and every large tech company, keeps a crack team of elite anthropologists busy at all times, with big budgets and carte blanche, reporting directly to the leadership team, right? (Looks around.) Oh. Instead they’re doing focus groups and user interviews, asking people in deeply artificial settings to project their usage of an alien technology in an unknown context, and calling that their anthropological, I’m sorry, their market research? Oh. I kid, I kid. Sort of, at least, in that I’m not sure a crack team of elite anthropologists would be all that much more effective. It’s hard enough getting an accurate answer of how a person would use a new technology when that’s the only variable. When they live in a constantly shifting and evolving world of other new technologies, when the ones which take root and spread have a positive-feedback-loop effect on the culture and mindset toward new technologies, and when every one of your first 20 interactions with new tech changes your feelings about it … it’s basically impossible. And so: painful trial and error, on all sides. Uber and Lyft didn’t think people would happily ride in strangers’ cars either; that’s why Uber started as what is now Uber Black, basically limos-via-app, and Lyft used to have that painfully cringeworthy “ride in the front seat, fist-bump your driver” policy. Those are the success stories. The graveyard of companies whose anthropological guesses were too wrong to pivot to rightness, or who couldn’t / wouldn’t do so fast enough, is full to bursting with tombstones. That’s why VCs and Y Combinator have been much more secure businesses than startups; they get to run dozens or hundreds of anthropological experiments in parallel, while startups get to run one, maybe two, three if they’re really fast and flexible, and then they die. This applies to enterprise businesses too, of course. Zoom was an anthropological bet that corporate cultures would make video conferencing big and successful if it actually worked. It’s easy to imagine the mood among CEOs instead being “we need in-person meetings to encourage those Moments of Serendipity,” which you’ll notice is the same argument that biased so many big companies against remote work and in favor of huge corporate campuses … an attitude that looks quaint, old-fashioned and outmoded, now. This doesn’t just apply to the deployment phase of technologies. The irruption phase has its own anthropology. But irruption affects smaller sectors of the economy, whose participants are mostly technologists themselves, so it’s more anthropologically reasonable for techies to extrapolate from their own views and project how that society will change. The meta-anthropological theory held by many is that what the highly technical do today, the less technical will do tomorrow. That’s a belief held throughout the tiny, wildly non-representative cryptocurrency community, for instance. But even if it was true once, is it still? Or is a shift away from that pattern to another, larger social change? I don’t know, but I can tell you how we’re going to find out: painful trial and error.

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/20/googles-sundar-pichai-doesnt-want-you-to-be-clear-eyed-about-ais-dangers/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9zbGFzaGRvdC5vcmcvP3BhZ2U9MQ&amp;guce_referrer_sig=AQAAAMoDCWISq1nsKUu7LjYH4A8Jvo5j4wuZNlwAQxJW_KUa2ud7-dxsF1dpUc5wi-l5CVHkJ9MeYHsxMeRTIcfMuGUV0ZA3JTWb4IeCzB5RU7QOt6KfHajDgbjNVsddZD9C1b0aMpKstYQFVz7Vn0H1w9D-DYAbvdVHUuiIArLQZKwq
### Query Relevance Score: 0.11122491955757141
### Highlights: None

Alphabet and Google CEO, Sundar Pichai, is the latest tech giant kingpin to make a public call for AI to be regulated while simultaneously encouraging lawmakers towards a dilute enabling framework that does not put any hard limits on what can be done with AI technologies. In an op-ed published in today’s Financial Times, Pichai makes a headline-grabbing call for artificial intelligence to be regulated. But his pitch injects a suggestive undercurrent that puffs up the risk for humanity of not letting technologists get on with business as usual and apply AI at population-scale — with the Google chief claiming: “AI has the potential to improve billions of lives, and the biggest risk may be failing to do so” — thereby seeking to frame ‘no hard limits’ as actually the safest option for humanity. Simultaneously the pitch downplays any negatives that might cloud the greater good that Pichai implies AI will unlock — presenting “potential negative consequences” as simply the inevitable and necessary price of technological progress. It’s all about managing the level of risk, is the leading suggestion, rather than questioning outright whether the use of a hugely risk-laden technology such as facial recognition should actually be viable in a democratic society. “Internal combustion engines allowed people to travel beyond their own areas but also caused more accidents,” Pichai writes, raiding history for a self-serving example while ignoring the vast climate costs of combustion engines (and the resulting threat now posed to the survival of countless species on Earth). “The internet made it possible to connect with anyone and get information from anywhere, but also easier for misinformation to spread,” he goes on. “These lessons teach us that we need to be clear-eyed about what could go wrong.” For “clear-eyed” read: Accepting of the technology-industry’s interpretation of ‘collateral damage’. (Which, in the case of misinformation and Facebook, appears to run to feeding democracy itself into the ad-targeting meat-grinder.) Meanwhile, not at all mentioned in Pichai’s discussion of AI risks: The concentration of monopoly power that artificial intelligence appears to be very good at supercharging. Funny that. Of course it’s hardly surprising a tech giant that, in recent years, rebranded an entire research division to ‘Google AI’ — and has previously been called out by some of its own workforce over a project involving applying AI to military weapons technology — should be lobbying lawmakers to set AI ‘limits’ that are as dilute and abstract as possible. The only thing that’s better than zero regulation are laws made by useful idiots who’ve fallen hook, line and sinker for industry-expounded false dichotomies — such as those claiming it’s ‘innovation or privacy’. Pichai’s intervention also comes at a strategic moment, with US lawmakers eyeing AI regulation and the White House seemingly throwing itself into alignment with tech giants’ desires for ‘innovation-friendly’ rules which make their business easier. (To wit: This month White House CTO Michael Kratsios warned in a Bloomberg op-ed against “preemptive, burdensome or duplicative rules that would needlessly hamper AI innovation and growth”.) The new European Commission, meanwhile, has been sounding a firmer line on both AI and big tech. It has made tech-driven change a key policy priority, with president Ursula von der Leyen making public noises about reining in tech giants. She has also committed to publish “a coordinated European approach on the human and ethical implications of Artificial Intelligence” within her first 100 days in office. (She took up the post on December 1, 2019 so the clock is ticking.) Last week a leaked draft of the Commission proposals for pan-EU AI regulation suggest it’s leaning towards a relatively light touch approach (albeit, the European version of light touch is considerably more involved and interventionist than anything born in a Trump White House, clearly) — although the paper does float the idea of a temporary ban on the use of facial recognition technology in public places. The paper notes that such a ban would “safeguard the rights of individuals, in particular against any possible abuse of the technology” — before arguing against such a “far-reaching measure that might hamper the development and uptake of this technology”, in favor of relying on provisions in existing EU law (such as the EU data protection framework, GDPR), in addition to relevant tweaks to current product safety and liability laws. While it’s not yet clear which way the Commission will jump on regulating AI, even the lightish-touch version its considering would likely be a lot more onerous than Pichai would like. In the op-ed he calls for what he couches as “sensible regulation” — aka taking a “proportionate approach, balancing potential harms, especially in high-risk areas, with social opportunities”. For “social opportunities” read: The plentiful ‘business opportunities’ Google is spying — assuming the hoped for vast additional revenue scale it can get by supercharging expansion of AI-powered services into all sorts of industries and sectors (from health to transportation to everywhere else in between) isn’t derailed by hard legal limits on where AI can actually be applied. “Regulation can provide broad guidance while allowing for tailored implementation in different sectors,” Pichai urges, setting out a preference for enabling “principles” and post-application “reviews”, to keep the AI spice flowing. The op-ed only touches very briefly on facial recognition — despite the FT editors choosing to illustrate it with an image of the tech. Here Pichai again seeks to reframe the debate around what is, by nature, an extremely rights-hostile technology — talking only in passing of “nefarious uses” of facial recognition. Of course this wilfully obfuscates the inherent risks of letting blackbox machines make algorithmic guesses at identity every time a face happens to pass through a public space. You can’t hope to protect people’s privacy in such a scenario. Many other rights are also at risk, depending on what else the technology is being used for. So, really, any use of facial recognition is laden with individual and societal risk. But Pichai is seeking to put blinkers on lawmakers. He doesn’t want them to see inherent risks baked into such a potent and powerful technology — pushing them towards only a narrow, ill-intended subset of “nefarious” and “negative” AI uses and “consequences” as being worthy of “real concerns”. And so he returns to banging the drum for “a principled and regulated approach to applying AI” [emphasis ours] — putting the emphasis on regulation that, above all, gives the green light for AI to be applied. What technologists fear most here is rules that tell them when artificial intelligence absolutely cannot apply. Ethics and principles are, to a degree, mutable concepts — and ones which the tech giants have become very practiced at claiming as their own, for PR purposes, including by attaching self-styled ‘guard-rails’ to their own AI operations. (But of course there’s no actual legal binds there.) At the same time data-mining giants like Google are very smooth operators when it comes to gaming existing EU rules around data protection, such as by infesting their user-interfaces with confusing dark patterns that push people to click or swipe their rights away. But a ban on applying certain types of AI would change the rules of the game. Because it would put society in the driving seat. Laws that contained at least a moratorium on certain “dangerous” applications of AI — such as facial recognition technology, or autonomous weapons like the drone-based system Google was previously working on — have been called for by some far-sighted regulators. And a ban would be far harder for platform giants to simply bend to their will. So for a while I was willing to buy into the whole tech ethics thing but now I’m fully on the side of tech refusal. We need to be teaching refusal. — Jonathan Senchyne (@jsench) January 16, 2020

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/30/business/artificial-intelligence-robots-retail.html
### Query Relevance Score: 0.0942080169916153
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times News subscription; current subscribers not eligible. Subscription excludes print edition. Subscription also excludes digital access to New York Times Games, Cooking, Wirecutter or The Athletic. Your payment method will automatically be charged in advance the introductory rate of $4 every 4 weeks for 1 year, and after 1 year the standard rate of $17 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/01/technology/personaltech/tech-trends-2020.html
### Query Relevance Score: 0.08673646301031113
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times All Access subscription; current subscribers not eligible. Subscription excludes print edition. Your payment method will automatically be charged in advance the introductory rate of $5.00 every 4 weeks for 1 year, and after 1 year the standard rate of $25.00 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/01/health/breast-cancer-mammogram-artificial-intelligence.html
### Query Relevance Score: 0.08277210593223572
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times News subscription; current subscribers not eligible. Subscription excludes print edition. Subscription also excludes digital access to New York Times Games, Cooking, Wirecutter or The Athletic. Your payment method will automatically be charged in advance the introductory rate of $4 every 4 weeks for 1 year, and after 1 year the standard rate of $17 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/29/technology/warehouse-robot.html?action=click&module=Top%20Stories&pgtype=Homepage
### Query Relevance Score: 0.08093620091676712
### Highlights: None

Credit...Video by Robert Rieger At a facility near Berlin, a new kind of robot is automating tasks that until recently had been out of the reach of machines. Credit...Video by Robert Rieger Jan. 29, 2020 LUDWIGSFELDE, Germany — Inside a warehouse on the outskirts of Berlin, a long line of blue crates moved down a conveyor belt, carrying light switches, sockets and other electrical parts. As they came to a stop, five workers picked through the small items, placing each one in a cardboard box. At Obeta, an electrical parts company that opened in 1901, it is the kind of monotonous task workers have performed for years. But several months ago, a new worker joined the team. Stationed behind protective glass, a robot using three suction cups at the end of its long arm does the same job, sifting through parts with surprising speed and accuracy. While it may not seem like much, this component-sorting robot is a major advance in artificial intelligence and the ability of machines to perform human labor. As millions of products move through warehouses run by Amazon, Walmart and other retailers, low-wage workers must comb through bin after bin of random stuff — from clothes and shoes to electronic equipment — so that each item can be packaged and sent on its way. Machines had not really been up to the task, until now. Image Credit...Robert Rieger for The New York Times “I’ve worked in the logistics industry for more than 16 years and I’ve never seen anything like this,” said Peter Puchwein, vice president of Knapp, an Austrian company that provides automation technology for warehouses. Standing nearby at the Obeta warehouse, the California engineers who made the robot snapped pictures with their smartphones. They spent more than two years designing the system at a start-up called Covariant.AI, building on their research at the University of California, Berkeley. Their technology is an indication that, in the coming years, few warehouse tasks will be too small or complex for a robot. And as the machines master tasks traditionally handled by humans, their development raises new concerns about warehouse workers losing their jobs to automation. Because the online retail business is growing so quickly — and most companies will be slow to adopt the latest robotic technologies — economists believe the advances will not cut into the overall number of logistics jobs anytime soon. But the engineers building these technologies admit that at some point most warehouse tasks will be done by machines. Human workers will need to find other things to do. The engineers at Covariant specialize in a branch of artificial intelligence called reinforcement learning. The machines are wired to learn new tasks on their own through extreme trial and error. And the best place to learn is in the real world. “If you want to advance artificial intelligence, you don’t just do it in a lab,” said Peter Chen, Covariant’s chief executive and co-founder. “There is a huge gap in bringing it to the real world.” Video A factory worker working alongside the Covariant robot. Currently, the robot is the only automated station in the packaging hall.CreditCredit...Video by Robert Rieger Warehouses are already highly automated. At the facility outside Berlin, inside a fenced-off room larger than a football field, other robots have long been used to fetch large boxes from shelves several stories high. But that is a relatively easy task for a machine. Engineers can program a robot to perform the same motion over and over again. The boxes are uniform. A robot can pick them up with the same motion every time. Picking through a bin of random items is different. Shapes vary, as do surfaces. One light switch might be upside down, the other right-side up. The next electrical gadget might be in a plastic bag that reflects light in ways a robot has never seen. A human touch has been needed. Programming a robotic arm to deal with every situation, one rule at a time, is impossible. At Knapp, Mr. Puchwein and his partners had tried and failed for years to create a robot with the dexterity and flexibility needed for the job. Image Credit...Robert Rieger for The New York Times Covariant, which is working with Knapp, built software that could learn through trial and error. First, the system learned from a digital simulation of the task — a virtual recreation of a bin filled with random items. Then, when Mr. Chen and his colleagues transferred this software to a robot, it could pick up items in the real world. The robot could continue to learn as it sorted through items it had never seen before. Inside the German warehouse, the robot can pick and sort more than 10,000 different items, and it does this with more than 99 percent accuracy, according to Covariant. This represents a significant change for the online retail and logistics industries. Late last year, the international robot maker ABB ran a contest. It invited 20 companies to design software for its robot arms that could sort through bins of random items, from cubes to plastic bags filled with other objects. Video Robots on tracks searching for the right tote in the stock to send it to the package station.CreditCredit...Video by Robert Rieger Ten of the companies were based in Europe, and the other half were in the United States. Most came nowhere close to passing the test. A few could handle most tasks but failed on the trickier cases. Covariant was the only company that could handle every task as swiftly and efficiently as a human. “We were trying to find weaknesses,” said Marc Segura, managing director of service robotics at ABB. “It is easy to reach a certain level on these tests, but it is super difficult not to show any weaknesses.” Knapp, which helped deploy the system outside Berlin, and ABB believe this technology can be used in similar warehouses. Covariant engineers believe their robots will improve with practice. As a robot in one warehouse learns better ways for picking up certain items, the information feeds back to what is essentially a central brain run by Covariant that will help operate machines. Dirk Jandura, the managing director of Obeta, said companies like his were under extreme pressure to be more efficient. Automation is a key way to keep costs low. Image Credit...Robert Rieger for The New York Times Like many warehouse operators, Obeta has trouble finding workers willing to do the monotonous work. Each picker handles about 170 orders an hour, or about three per minute, over an eight-hour day. In the summer, temperatures in the warehouse reach more than 100 degrees. It is hard to keep employees for longer than six months. For Obeta, the new robot is an ideal solution. A job that requires three humans is done by one tireless robot. “It doesn’t smoke, is always in good health, isn’t chatting with its neighbors, no toilet breaks,” Mr. Jandura said. “It’s more efficient.” Knapp is also considering the design of warehouses staffed by robots rather than humans that would allow for packages to be more densely packed into spaces and retrieved by robots trained to perform the task. “The new warehouses will be built around A.I. robots and not humans,” Mr. Puchwein said. Knapp plans to make it hard for companies to say no to replacing human workers with robots. Mr. Puchwein said they would charge a fee that was always lower than what a company would pay a human. If a company paid $40,000 per year to a worker, Knapp would charge about $30,000, he said. “We just go lower,” he said. “That’s basically the business model. For the customer, it’s not very hard to decide.” Image Credit...Robert Rieger for The New York Times Beth Gutelius, associate director of the Center for Urban Economic Development at the University of Illinois at Chicago, who has studied the impact of automation on work, said this kind of technology was unlikely to shift the job market any time soon. The greater problem, she said, is that as humans work alongside robots, they will be judged in new ways. “As we start to compare the speed and efficiency of humans to robots, there is a whole new set of health and safety issues that emerge,” she said. Pieter Abbeel, a Berkeley professor who is a co-founder of Covariant as well as its president and chief scientist, said humans would continue to work alongside machines in these kinds of warehouses. But he acknowledged that the job market would significantly shift as machine learning improved. Image Credit...Robert Rieger for The New York Times “If this happens 50 years from now, there is plenty of time for the educational system to catch up to the job market,” he said. At the German warehouse, a woman in a baggy T-shirt diligently sorted through the boxes, occasionally looking up at the English-speaking visitors who were taking pictures of the robot and were marveling at its effectiveness. A Covariant engineer walked over to the group to share that the robot had filled more than 200 orders in the past hour, enough to receive a bonus if it were a human. Adam Satariano reported from Ludwigsfelde, and Cade Metz from San Francisco.

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/ces-2020-virtual-reality-artificial-intelligence-and-a-small-glimpse-of-the-future
### Query Relevance Score: 0.11163276433944702
### Highlights: None

Hyundai's S-A1 expects to hit production in 2028 to begin supplying Uber for its air taxi service. (Ben Brown/ Fox News) Flying taxis, virtual reality, artificial intelligence, and even a new energy drink were among the products that graced the convention floor at this year’s Consumer Electronics Show (CES). You can find yourself spending hours walking the seemingly endless halls filled with the latest technology propelling the world into the future. And, while it’s virtually impossible to see everything that CES has to offer, below are just a few items that caught the eye of Fox News. SEGWAY S-POD Instead of standing, the Segway S-Pod takes comfort one step further by allowing the user to sit, shifting their center of gravity for a smooth ride that is eerily reminiscent of the hover chairs in the popular Pixar movie, “Wall-E.” The S-Pod can reach up to 24 mph. (Ben Brown / Fox News) “It is the first-class transporting pod designed for everybody. So, we are envisioning this as part of the future of this smart city,” Jeff Wu, marketing and growth lead at Segway told Fox News. “We can see it in enclosed campuses, in our shopping malls and the airport, for example.” After the chair finds its center of gravity, the user can glide around up to 24 miles per hour navigating with a simple joystick. The S-pod can travel up to 43 miles on a single charge. Wu said the inspiration behind the design came from the gyro sphere featured in the 2015 “Jurassic World” movie starring Chris Pratt, telling Fox News it “really feels like they are flying, levitating when they are navigating” the S-Pod. There is currently no price point set for the S-pod but it will be available for consumers in 2021. “Starting off it will definitely be more of private use in enclosed campuses, but essentially in the future, maybe, you know, for the rideshare pickup, people will be able to use their cell phone to call something like a Segway as part to pick them up to complete a transportation from A to B,” Wu told Fox News, adding that there is more exciting news to come soon. HACHI INFINITE Forget lugging that bulky computer around. The Hachi Infinite can turn any flat surface into a computer. (Ben Brown / Fox News) The Hachi Infinite can turn any flat surface into a fully-interactive touch screen computer, equipped with web-browsing, Microsoft Word and Excel. “It has built-in Android OS 9.0 … It's a computer. It works just like a tablet or your phone on any flat surface,” Hannah Wilkinson, marketing for Hachi told Fox News. “You can use Microsoft Word, you can use YouTube, you can search the Internet, you can play Candy Crush, you can do anything on this -- anything you could do on a computer or your phone.” It essentially looks like a portable mini projector and has brightness sensors so it can be used indoors and outdoors, even on a sunny day. In addition to functioning like a computer, the device can flip on its other side to be used as the ultimate movie viewing experience with a 120 inch HD display and an ultra-short throw DLP built-in,” Wilkinson said. The Hachi Infinite also has built-in artificial intelligence capabilities, including the ability to identify foods and offer up unique dinner recipes centered around that identified item. “There's already three A.I. functionalities built right into it -- So, it can recognize objects and uses deep learning algorithms. There's a variety of learning experiences for children, cooking experiences -- it can recognize any kind of fruit or vegetable in front of it and tell you the nutritional information, tell you recipes you can use with it,” Wilkinson said, adding that “Hachi is developing a number of apps that work with A.I. functionalities.” COKE ENERGY An energy drink that tastes like your favorite soda … no wonder it made it onto the CES floor. Coca-Cola Energy hits shelves on January 20th. (Ben Brown / Fox News) Coca-Cola is trying to shake-up the buzzing energy drink market with its own tasty concoction. No longer does one have to choose between an energy drink or a soda to provide that much-needed caffeine boost throughout the day, because Coca-Cola has come up with the solution – Coca-Cola Energy. “Coca-Cola has always looked at a consumer-focused approach to innovation, and as we learned about consumers and what they were looking for in the US, we learned that they love Coca-Cola. They love the uplift of Coke,” Jaideep Kibe, vice president for Coca-Cola trademark in the United States told Fox News. “But there are moments in their day when they want that extra boost, but they want it in a way that's familiar and approachable -- and that's how Coke Energy was born.” The new beverage unveiled at this year’s CES comes in four flavors: Coca-Cola Energy, Coca-Cola Energy Zero, Coca-Cola Energy Cherry and Coca-Cola Energy Cherry Zero. A regular Coke is about 34 grams of caffeine, but the recipe for this [Coca-Cola Energy} is like that of an energy drink. So it does have 114 grams of caffeine. It has Guarana and it has B vitamins,” Kibe said. “So, it's comparable to all the leading energy drinks, but it has the familiar and approachable taste of Coca-Cola, which people know and love.” Coke partnered with Amazon’s Alexa to create an interactive booth that allowed CES attendees to get some of the first sips of the new energy drink that is set to hit the market on January 20th. “Coca-Cola has always been at the forefront of innovation. Our choices have always been driven not by ourselves, but by what our consumers were looking for,” Kibe said. “And when you look at the energy category around the world, and most especially in the U.S., there's a lot of growth, there's a lot of need thanks to our modern-day lifestyles for that extra boost and an extra kick.” CYBERSHOES While companies have made great strides in virtual reality gaming, there are limitations to how truly “interactive” the experience can be when you’re confined certain amount of space – whether you’re playing inside an apartment or at an arcade. Cybershoes allows users to run and walk-in virtual reality games. (Ben Brown / Fox News) Cybershoes might just be the first step into figuring out a solution to adding another layer into immersing the user into the game. For about $360 gamers can purchase the Cybershoes Gaming Station, which includes the shoes along with a cyberchair and cybercarpet. The Cybershoes strap on over your normal footwear and have a wheel attached to the bottom allowing the user to sit in the cyberchair and mimic walking/running while remaining sit. The motions then translate into the game and voila! no more stationary gaming – and it is actually quite the workout! HYUNDAI S-A1 FLYING TAXI Traffic jams and flat tires might soon be a thing of the past, as Hyundai and Uber Elevate are teaming up to offer a new way to travel. Hyundai unveiled its full-scale concept Urban Mobility Vehicle dubbed the S-A1, which essentially looks like a souped-up helicopter that Uber will use for its flying taxi service. “This is a game-changer for the aerospace industry because historically production rates have been fairly low in aviation. When you bring the capabilities of an automaker to this sector, it creates an opportunity for scale as it relates to the production and that can make sure that technology gets in the hands of more people around the world,” Wyatt Smith, head of business development of Uber Elevate told Fox News. Uber Air would work similarly to how Uber operates now – with a push of a button a car would pick you up and take you to a Skyport where an Urban Air Mobility (UAM) vehicle is waiting to fly you to the next hub most proximate to your destination. The passenger will then hop in another car that will take them the rest of the way. The S-A1 would just be one component of the urban air mobility ecosystem connecting the whole network together to allow passengers to get from point A to B. While this might all sound farfetched and lightyears away, both Hyundai and Uber expect the next form of consumer transportation to hit the market within the next decade. TRUMEDIC’S $5,500 MASSAGE CHAIR TruMedic’s InstaShiatsu+ Massage Chairs can be found in celebrity homes like the Kardashians, but it'll cost you a pretty penny. TruMedic’s InstaShiatsu+ Massage Chairs range in price from a few hundred dollars up to $5,500. (Ben Brown / Fox News) If you have a few thousand dollars and want to be pampered like a celebrity, the full-body massage chair will do the trick – from your arms to your waist to your neck and shoulders, this chair does it all. However, there are less expensive options that don't come with as many bells and whistles. Prices range from as low as $400 to as high as $5,500. In addition to the massage chairs, truMedic offers a cheaper but just as effective option dubbed the MagicHands truShiatsu Neck and Back Massager which has deep-kneading massage nodes that act like a human “thumb” to help penetrate sore muscles or offer an effective pre-workout warmup. The Magichands retail for $299.95 and is a favorite among celebrities like Hailey Bieber, Lily Aldridge, Joan Smalls, Winnie Harlow. MagicHands truShiatsu Neck and Back was selected for Oprah’s Favorite Things in December 2019. (Ben Brown / Fox News) MagicHands was also selected for Oprah’s Favorite Things in December 2019. "We’re pioneering the category of ‘Intelligent Wellness,’ and in doing so, truMedic is creating a world beyond relief,” Russell Izzo, truMedic CEO said. “With our newest innovations, consumers will experience amazing new designs with cutting edge form and functionality that deliver ultimate relaxation and recovery in the comfort of their homes and on-the-go. We spent years delighting customers with our quality and commitment to this category and we are excited to be leading its evolution into the next decade.”

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/artificial-intelligence-satellite-images-exports-china-us-restrictions
### Query Relevance Score: 0.10697858035564423
### Highlights: None

Beginning Monday, technology companies in the U.S. will face new restrictions on exporting some of their more state-of-the-art products to China and elsewhere, according to the Commerce Department. These new export rules — for companies building artificial intelligence software for analyzing satellite imagery — are targeting emerging technology that could give the U.S. a significant military or intelligence advantage. A special license would be required to sell software outside the U.S. that could scan aerial images automatically to identify objects of interest, such as vehicles or houses. U.S. WILL DOUBLE EXPORTS TO CHINA UNDER 'PHASE ONE' DEAL: LIGHTHIZER The rules could affect a growing sector of the technology industry using algorithms to analyze satellite images of crops, trade patterns and other changes affecting the economy or environment. The new export rules are coming after Congress passed a law in 2018 that updated national security-related export controls to protect “emerging and foundational” technology that could end up in the hands of foreign governments. It’s an interim rule until the public has a chance to weigh in before March. Commerce Department officials said it’s in the national-security interests of the U.S. to implement the controls immediately Monday. CLICK HERE TO GET THE FOX NEWS APP The department didn’t return Fox News’ request for comment via email Sunday night. The Associated Press contributed to this report.

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/google-just-created-the-most-detailed-image-of-a-brain-yet
### Query Relevance Score: 0.10523243248462677
### Highlights: None

Scientists created the most detailed map of a brain to date. This connectome depicts the neurons and synapses present in one-third of a fruit fly's brain. (Credit: FlyEM/Janelia Research Campus) Scientists have created the most detailed 3D map of an organism brain to date. The mesmerizing threads of blue, yellow, purple and green represent thousands of brain cells and millions of connections found inside the brain of a fruit fly. This high-resolution map, known as a "connectome," only makes up one-third of a fruit fly's brain but includes a large region involved in learning, navigation, smell and vision. Scientists found over 4,000 different types of neurons, including those involved in the fly's circadian rhythm — or internal clock — that might help researchers learn a bit more about how the insect sleeps, according to the publicly released data. This map, a collaboration between scientists at Google and the Janelia Research Campus in Virginia, took two years to create. The team started out by cutting a fruit fly brain into extremely thin slices using a hot knife — and then imaging each slice under an electron microscope. Afterward, they stitched the images together to create a large map, tracing the paths of the neurons through the brain, according to the statement. Related: 3D Images: Exploring the Human Brain The point of such maps is to reveal something about how specific physical connections in the brain are linked to distinct behaviors. But following each individual neuron in a journey across the brain is painstaking work — and critics note that such maps have not yet led to a major discovery, according to The Verge. The only organism to have its entire brain mapped this way is the roundworm C. elegans — a wriggly critter that only harbors around 300 to 400 neurons and around 7,000 synapses, or the junctions between brain cells. Other teams have attempted to map the human brain in lower resolution. But considering that the human brain contains 86 billion neurons, creating such a map will likely take some more time. The new map was published on Jan. 21 in the database BioRxiv, and it has not yet been peer reviewed. Inside the Brain: A Photo Journey Through Time Check Out These Amazing Super-Detailed Images of Fruit Fly Brains Dazzling Images of the Brain Created by Neuroscientist-Artist Originally published on Live Science.

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/amazon-patent-shows-robots-that-could-drop-off-bunches-of-items-on-sidewalks
### Query Relevance Score: 0.10369698703289032
### Highlights: None

Amazon is testing robots that can store packages and make multiple deliveries along their routes, according to a new patent filing. According to the patent application published Tuesday, the tech giant's proposed storage compartment vehicles (SCV) could also pick up items for return. The Seattle-based company, which already deploys robots in many of its fulfillment centers worldwide, is looking for ways to address the troublesome "last mile" of delivery with this method, which would have customers come outside on the sidewalk, tap a security code on their phones and open the correct door to get their packages. Alternate designs for Amazon’s storage compartment vehicle are adapted for aerial (left) or water-based (right) transportation. (Amazon Illustration via USPTO) (Amazon Illustration via USPTO) However, Amazon has often said its patent applications are meant to explore possibilities, but many inventions are not turned into products or services as described in patent applications. In certain parts of Seattle, Amazon has already been testing Amazon Scout delivery robots. According to GeekWire, the patent application points out that the SCVs could position themselves in predetermined areas and that they could be outfitted with cameras, microphones, GPS devices, biometric scanners and more -- to make sure no one messes with the robots and that deliveries arrive on time. CLICK HERE TO GET THE FOX NEWS APP There's also reportedly a water-based model that comes equipped with floats for marine delivery applications.

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war.print
### Query Relevance Score: 0.10009358823299408
### Highlights: None

By , Kris Osborn Published January 06, 2020 File photo - A 10th Mountain Division Soldier fires an M4 rifle during a platoon Situational Training Exercise at a range in Arta, Djibouti, Aug. 25, 2018. (U.S. Air Force photo by Senior Airman Haley D. Phillips) Targets emerge in seconds, incoming enemy fire puts lives at risk and shifting combat dynamics require immediate, on-the-spot decisions in a matter of seconds -- all as soldiers navigate the complex web of threats during all-out, high-risk ground-warfare. These kinds of predicaments, which characterize much of what soldiers train to face, are immeasurably improved by emerging applications of AI; artificial intelligence can already gather, fuse, organize and analyze otherwise disparate pools of combat-sensitive data for individual soldiers. Target information from night vision sensors, weapons sights, navigational devices and enemy fire detection systems can increasingly be gathered and organized for individual human soldier decision-makers. However, what comes after this? Where will AI go next in terms of changing modern warfare for Army infantry on the move in war? The Army Research Laboratory is now immersed in a complex new series of research and experimentation initiatives to explore a “next-level” of AI. Fundamentally, this means not only using advanced algorithms to ease the cognitive burden for individual soldiers -- but also network and integrate otherwise stovepiped applications of AI systems. In effect, this could be described as performing AI-enabled analytics on groups of AI systems themselves. “Autonomy is doing things in a snipped way that can be connected. We can benefit from an overarching AI approach, something that looks at the entire mission. Right now our autonomy solves very discreet problems that are getting more complicated,” J. Corde Lane, Ph.D., director, Human Research and Engineering, CCDC-Army Research Laboratory, told Warrior in an interview. F-35 SET FOR LASER BOOST What does this mean? In essence, it translates into a way combat commanders will not only receive AI-generated input from individual soldiers but also be able to assess how different AI systems can themselves be compared to one another and analyzed as a dynamic group. For instance, Lane explained, perhaps multiple soldier-centric AI-empowered assessments can be collected and analyzed in relation to one another with a mind to how they impact a broader, squad-level combat dynamic. In particular, simultaneous analysis of multiple soldier-oriented AI system can help determine the best course of action for an entire unit, in relation to an overall mission objective. “What is the entire mission and possible courses of action? Do we optimize the logistics flow? Find targets as the dynamic battlefield gets more complex? The Commander can draw upon advanced AI to explore new options,” Lane explained. Therefore, in addition to drawing upon algorithms able to organize data within a given individual system, future AI will encompass using real-time analytics to assess multiple systems simultaneously and how they impact one another to offer an overall integrated view. All of this progress, just as is the case now, will still rely heavily upon human decision-making faculties to optimize its added value for combat. Integrating a collective picture, drawing upon a greater range of variables will require soldiers to incorporate new tactics and methods of analysis to best leverage the additional available information. SOLDIERS USE AI TO FIRE PRECISION GRENADES, GUIDE DRONE ATTACKS “When we have new and improved autonomy coming in, soldiers need to know how to use that. How do you keep the soldier always at the center and adapt to them as you adapt to the new AI?” Lane asked. Perhaps one soldier receives organized sensor-driven targeting data relevant to a specific swath of terrain, while another AI system is organizing variables to determine the supply flow of ammunition, fuel or other logistical factors. “Data never seen cannot be learned. It is not about AI, but combining AI with a soldier who has the concept of an entire mission. AI provides information and then they get put together. When you are under fire, you are going to need different types of information,” Lane explained. For example, comparing and analyzing various AI systems to help engender a collective picture of some kind might enable a commander to know “if you go this way you will use more fuel but it will be safer,” as Lane explained. HOW AI CHANGES ATTACK MISSIONS FOR US FIGHTER JETS AND BOMBERS Interestingly, Lane’s point about the irreplaceable characteristics of human cognition in the face of new AI-driven technologies is anticipated in a 2017 essay from the Chatham House Royal Institute of International Affairs, called “Artificial Intelligence and the Future of War.” The essay, written by M.L. Cummings, states that “replicating the intangible concept of intuition, knowledge-based reasoning and true expertise is, for now, beyond the realm of computers.” Mathematically oriented computer algorithms naturally face limitations when it comes to things like judgments, feelings or quickly assessing not-yet-seen information; an AI-database can only be as effective as the information it already has stored in its database. While Machine-Learning techniques continue to accelerate the pace at which an existing AI database can quickly integrate and perform analytics on new information, AI-infused computing can only make decisions or solve problems in relation to the information it already has stored. Now it goes without saying that these databases are increasingly vast, almost seeming limitless, yet they do need to consistently be fed with not-yet-stored information of great relevance to wartime decisions. CLICK HERE TO GET THE FOX NEWS APP The Chatham House essay puts it this way: “Every autonomous system that interacts in a dynamic environment must construct a world model and continually update that model. This means that the world must be perceived (or sensed through cameras, microphones and/or tactile sensors) and then reconstructed in such a way that the computer ‘brain’ has an effective and updated model of the world it is in before it can make decisions. The fidelity of the world model and the timeliness of its updates are the keys to an effective autonomous system.” (Artificial Intelligence and the Future of War” M.L. Cummings) URL https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/spot-boston-dynamics-robot-hyundai-noise-cancelling-genesis/
### Query Relevance Score: 0.09146508574485779
### Highlights: None

Hyundai is solving and robots are evolving, but first: a cartoon about parental phone tracking. Here's the news you need to know, in two minutes or less. Want to receive this two-minute roundup as an email every weekday? Sign up here! Today’s News Spot the robot dog trots into the big, bad world You've probably seen the videos of Boston Dynamics' incredible (and creepy) robot dog Spot opening doors, trotting in parking lots, and fending off stick-wielding humans. But a few months ago, 75 of them got out of the house and found jobs working in places like construction companies and mining outfits. How are things going? Pretty well! New software updates released today will allow companies to further customize Spot to their needs, but the robots still needs a lot of paw-holding in the unpredictable outside world. It seems, for now, the robot revolution may be more about assisting humans than replacing them. Hyundai's luxury SUV mixes mics and math for a silent ride Most luxury cars boast a quiet ride; some even use noise-canceling technology to mask the steady hum of the engine. But noises like rolling tires change as you ride along, demanding a smarter system to keep things quiet. So Hyundai has deployed vibration-calculated accelerometers, amplifiers, and multiple microphones in the company's new Genesis GV80 SUV, giving each seat a dedicated signal tailored to what the car’s interior mics detect at each position and cutting in-cabin noise in half. Fast Fact: 11 Million That's about how many people live in the city of Wuhan, China, which is now in lockdown due to the spread of the mysterious coronavirus. Will shutting down transportation in and out of the city work? Experts can't be sure, but it's next to impossible to lock down a city of that size, and the virus has already spread to at least five other countries so far. WIRED Recommends: Compact Mechanical Keyboards There's nothing quite like the clickety-clack springiness of a mechanical keyboard, but their bulk can make them tough travel companions. That's why our writers made a list of the compact mechanical keyboards all the cool kids are using. News You Can Use Here's how to buy used gear on eBay—the smart, safe way. This daily roundup is available as a newsletter. You can sign up right here to make sure you get the news delivered fresh to your inbox every weekday!

---

## Article published: 01/2020
### Source URL: https://www.wired.com/video/genres/technology
### Query Relevance Score: 0.08861994743347168
### Highlights: None

Technology Every rocket launch is different and it takes a lot of people and safety checks to ensure that a 5.75 million pound rocket can safely launch into space. Mike Massimino, a former NASA astronaut and spacecraft communicator in the Mission Control Center breaks down what happens from eight hours before liftoff until launch. Director: Katherine Wzorek Director of Photography: Brad Wickham Edito: Joshua Pullar Expert: Mike Massimino Producer: Katherine Wzorek Associate Producer: Paul Gulyas Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Jack Belisle Sound: Jeff Gaumer Production Assistant: Ryan Coppola Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Technology Arun Maini, better known as Mrwhosetheboss, takes the WIRED Autocomplete Interview and answers the internet's most searched questions about himself. Where did the name Mrwhosetheboss come from? Why is his name spelled wrong? What kind of camera does he use? What kind of phone does he use? Is he legit? Arun answers all these questions and much more! Director: Anna O'Donohue Director of Photography: Kris Anwar Editor: Parker Dixon Talent: Arun Maini Producer: Katherine Wzorek Line Producer: Joseph Buscemi Associate Producer: Brandon White Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: John Whatton Audio: Nick Ware Production Assistant: Jack Haynes Groomer / Hair & Make-Up: Niki Mark Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Andy Morell Science The Earth has had five extinction events and five long recoveries. Steve Palumbi, Professor of Biology, Stanford University, discusses what will happen after a sixth event and how human technology can speed up the process. Technology A fiber laser can carve super intricate designs into any metal in just 10 seconds. The laser is getting so hot the metal is vaporizing away, yet it does nothing to our skin. As we play the video back and watch these lasers in slow motion, Alexander Sellite of "Laser Everything" breaks down everything we need to know about fiber lasers and how they function. See more of Alex here: https://www.youtube.com/LaserEverything Culture Alan Ahn, senior resident fellow of the Climate and Energy program at Third Way, an organization that advocates for sustainable nuclear power, will take the stage to discuss the future of nuclear power in the United States and how recent events in Ukraine and Japan have changed people’s perceptions of nuclear energy as a clean solution. Culture Doria Robinson, executive director of Urban Tilth, discusses how climate change disproportionately impacts communities of color and low-income populations. She shares her experiences with urban farming, which can ease the strain on global food chains, enrich and enliven communities, and help communities feed themselves without having to rely on massive agricultural networks. Science Photographer Camille Seaman has spent years documenting our changing world through her lens. In this talk she shares some of her most striking work. Culture James McBride, cofounder and chief technology officer of Otherlab, will discuss some of the innovative solutions he and his team are working on to reduce our use of fossil fuels and decarbonize the world. Business WIRED science writer Matt Simon guides us through several conversations focused on actionable solutions to problems in our communities, speaking first with Global Footprint Network chief science officer David Lin and president Mathis Wackernagel, who lead attendees through a “choose your own adventure” activity where everyone evaluates how much "Earth" they take up and what the impact of continued growth will be on our society. Business Colette Pichon Battle, climate activist, lawyer, and partner at Taproot Earth, is on the front lines in the Louisiana bayou fighting to protect vulnerable communities from suffering the worst effects of climate change. Culture Alan Ahn, senior resident fellow of the Climate and Energy program at Third Way, an organization that advocates for sustainable nuclear power, will take the stage to discuss the future of nuclear power in the United States and how recent events in Ukraine and Japan have changed people’s perceptions of nuclear energy as a clean solution. Culture Patricia Hidalgo-Gonzalez, assistant professor at UC San Diego, discusses our electrical grid and the goal of “making everything electric” to reduce reliance on fossil fuels. But that in itself is not enough, she says. Our goal must be to build resilient energy systems that can operate sustainably and incorporate clean energy solutions. She starts by discussing what we can do today, then takes us forward into what a clean, resilient grid might look like decades from now.

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/wuhan-coronavirus-ai-mac-malware-shlayer-trojan/
### Query Relevance Score: 0.08858482539653778
### Highlights: None

Artificial intelligence is alerting and Mac malware is diverting, but first: a cartoon about baby privacy. Here's the news you need to know, in two minutes or less. Want to receive this two-minute roundup as an email every weekday? Sign up here! Today’s News An AI epidemiologist sent the first warnings of the Wuhan virus On January 9, the World Health Organization notified the public of a flu-like outbreak in Wuhan, China, that led to city lockdowns affecting tens of millions of people. But a Canadian health monitoring platform sent news of the outbreak to its customers more than a week earlier, on December 31. The platform, called BlueDot, uses an AI-driven algorithm that scours foreign-language news reports, animal and plant disease networks, and official proclamations to give its clients advance warning to avoid danger zones like Wuhan if possible. The sneaky simple malware that hits millions of Macs This week, a report from antivirus company Kaspersky revealed that the most common threat to Mac computers is the Shlayer Trojan, which has hit 10 percent of all of the Macs Kaspersky monitors and accounted for nearly a third of detections overall. It’s had the top spot since it first emerged in February 2018, and is deceptively simple: Users download the software either as phony Adobe Flash downloads or masked links on popular internet pages. Because users are downloading the software themselves, it's nearly impossible for Apple to defend against it. But you can by following this advice: Never click suspicious links, especially not in surprise popup windows. Fast Fact: 5 That's how many Grammy awards musician Billie Eilish won last night. At just 18 years old, she became the youngest person ever to be nominated for and win the four major awards: Best Album, Best Song, Best New Artist, and Best Record. WIRED Recommends: Running Gear The hardest part of running is just getting out the door—especially in winter when it's cold and wet. But—you guessed it—there's gear for that. No more excuses! News You Can Use How to raise media-savvy kids in the digital age. This daily roundup is available as a newsletter. You can sign up right here to make sure you get the news delivered fresh to your inbox every weekday!

---

## Article published: 01/2020
### Source URL: https://www.wired.com/video/new
### Query Relevance Score: 0.08832038938999176
### Highlights: None

Skip to main content Culture Danny Gonzalez takes the WIRED Autocomplete Interview and answers the internet's burning questions about himself. Who is Greg? Does Danny still work for Corridor? Is he going to quit YouTube? Does he use autotune? Danny answers all these questions and much more! Check out Danny's channel: https://www.youtube.com/@Danny-Gonzalez Director: James Herron Director of Photography: AJ Young Editor: Jeremy Smolik Talent: Danny Gonzalez Talent Booker: Mica Medoff Producer: Alexandria Coccia Line Producer: Joseph Buscemi Associate Producer: Melissa Cho Production Manager: Eric Martinez Production Coordinator: Fernando Davila Audio: Paul Cornett Cam Op/Gaffer: Omar Elgohary Production Assistant: Ariel Labasan Groomer: Vanessa Ren Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Billy Ward How-To We visit Jack White's Third Man Records vinyl pressing plant in Detroit, Michigan to find out exactly what goes into the creation of a vinyl record; from cutting and pressing to making sure they sound great. Find out more here: https://thirdmanpressing.com https://www.instagram.com/thirdmanpressing/ Director: Katherine Wzorek Director of Photography: Kevin Hewitt Editor: Louis Lalire Talent: Broc Barnes, Warren Defever, Ed Gillis Line Producer: Joseph Buscemi Associate Producer: Samantha Vélez Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Kevin Ward Audio: Frank Biondo Production Assistant: Ryan Hewitt Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Justin Symonds Culture It's not rocket science! Well, actually, it is! Rocket scientists Tiera and Myron Fletcher answer the internet's burning questions about rocket science, rocket ships and space travel. What's harder, rocket science or brain surgery? Will humanity ever leave the solar system? What's so special about Elon Musk's new rocket? Why are rocket engines so loud? Will we eventually have warp drive? Tiera and Myron answer all these questions and much more! Director/Producer: Lisandro Perez-Rey Director of Photography: Kevin Harrington Editor: Joshua Pullar Talent: Tiera & Myron Fletcher Line Producer: Joseph Buscemi Associate Producer: Paul Gulyas Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Ingrid Thronson Audio: Tim Wolfe Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Paul Tael Culture While the concept of infinity may seem mysterious, mathematicians have developed processes to reason the strange properties of infinity. Mathematician Emily Riehl has been challenged to explain infinity to 5 different people; a child, a teen, a college student, a grad student, and an expert. Director: Maya Dangerfield Producer: Wendi Jonassen Director of Photography: Ben Finkel Editor: Louville Moore Host: Emily Riehl Level 1: Samira Sardella Level 2: Eris Busey Level 3: Yoni Singer Level 4: Elliot Lehrer Level 5: Adriana Salerno Line Producer: Joseph Buscemi Associate Producer: Paul Gulyas Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Larry Greenblatt Gaffer: Randy Feldman Audio: Ken Pexton Production Assistant: Andrea Hines Hair/Makeup Artist: Haki Pope Johns Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Paul Tael Culture Did you play with slinkys when you were younger? Josh Jacobs has taken a childhood toy and turned it into a visually stunning art form. Slinky manipulation is a fairly new practice, starting around 2010. Josh got into "slinking" eight years ago when watching an incredible Chinese performer do things he never thought possible with a slinky. Now, Josh is one of the best slinky manipulators in the world. Check out Josh's channel here: https://www.youtube.com/@SlinkyJosh Director: Charlie Jordan Director of Photography: Colin Witherill Editor: Richard Trammell Talent: Joshua "Slinky Josh" Jacobs Producer: Wendi Jonassen Line Producer: Joseph Buscemi Associate Producer: Melissa Cho Production Manager: Eric Martinez Production Coordinator: Fernando Davila Audio: Ted Thacker Cam Op/Gaffer: Alex Witkowicz Production Assistant: Daniel Ellis Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Ben Harowitz Science Produced by WIRED Brand Lab with Labcorp | One of the biggest challenges for people with Alzheimer’s Disease and their caregivers is the path to a correct diagnosis. Recent advancements in biomarker technology are about to change that by measuring neurodegeneration in the brain, differentiating Alzheimer’s from other forms of neurodegenerative disorders, and even producing a diagnosis years before symptoms appear. Dr. Marcia Eisenberg, Chief Scientific Officer at Labcorp, shares the development of these technologies and their implementation, physician and Professor of Neurology Dr. Marwan Sabbagh speaks to the impact of these advancements and Jamie Haendel shares her personal experience with the disease, as daughter and caregiver to Paula Haendel, a woman diagnosed with Alzheimer’s. Culture The scoop on the innovative and inclusive designs L’Oreal brought to the show Culture Scientist and Immunologist Dr. Shruti Naik answers the internet's burning questions about our immune systems. Are viruses alive? Is chicken soup actually good for the immune system? What does the spleen even do? Is playing in dirt good for your child's health?? Dr. Shruti answers all these questions and much more! Director: Justin Wolfson Director of Photography: Brad Wickham Editor: Chris Davies Expert: Dr. Shruti Naik Line Producer: Joseph Buscemi Associate Producer: Brandon White Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Brittany Berger Audio: Sean Paulsen Production Assistant: Ryan Coppola Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Andy Morell Culture ITZY take the WIRED Autocomplete Interview and answer the internet's most searched questions about themselves. What does ITZY mean? Who joined ITZY first? What is their fanchant? Can they speak Japanese? How were they discovered? Yeji, Lia, Ryujin, Chaeryeong, and Yuna answer all these questions and much more! Director: Katherine Wzorek Director of Photography: Jack Belisle Editor: J.Y. Chun Talent: ITZY Producers: Alexandra Coccia, Katherine Wzorek Line Producer: Joseph Buscemi Associate Producer: Samantha Vélez Production Manager: Eric Martinez Production Coordinator: Fernando Davila Talent Booker: Paige Garbarini Gaffers: Devan Davies and Gautam Kadian Audio: Reh Chandan and Spencer Ward Production Assistant: Louis Coccia and Justine Ramirez Translator: Jenny An Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Ben Harowitz Culture The infection from HBO's The Last of Us is actually based on a real parasitic fungus. This fungus turns insects into zombies. The creators of the game and the show were inspired by zombie carpenter ants. WIRED spoke with Dr. Charissa de Bekker to talk about the real fungus that inspired the show's infected, and how the show's zombies parallel these real-life ants. Director: Lisandro Perez-Rey Editor: Ron Douglas Expert: Dr. Charissa de Bekker Line Producer: Joseph Buscemi Associate Producer: Brandon White Production Manager: Eric Martinez Production Coordinator: Fernando Davila Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editors: Andy Morell, Paul Tael Culture At the Missoula Fire Sciences Lab, scientists research the elements that make up forest fires. In this episode of WIRED Field Trip, we take a tour of this facility and learn how these teams develop a greater understanding of wildfires. Director: Alice Roth Editor: Lous Lalire Researchers: Steve Baker, Mark A Finney, Serra J. Hoagland, Sharon Hood, Jim Reardon Coordinating Producer: Kevyn Fairchild Line Producer: Joseph Buscemi Associate Producer: Amy Haskour Field Producer: Katherine Wzorek Production Manager: Eric Martinez Production Coordinator: Fernando Davila Fact Checker: Kelsey Lannin Post Production Supervisor: Alexa Deutsch Supervising Editor: Doug Larsen Assistant Editor: Diego Rentsch Special Thanks : Thomas Dzomba Archival and Additional Footage Credits Messengers: The Owls of Mescalero Directed by Janey Fugate US Department of Agriculture Culture Pascal Wallisch, NYU Professor of Psychology and Data Science, answers the internet's burning questions about illusions. What is motion-induced blindness? How do mirages happen? What's the explanation for "The Dress"? How did they make the Tupac hologram? Pascal answers all these questions and much more! For more on these illusions: https://www.foxlabnyu.com/techsupportreferences Director: Justin Wolfson Director of Photography: Brad Wickham Editor: Joshua Pullar Expert: Pascal Wallisch Line Producer: Joseph Buscemi Producer: Justin Wolfson Associate Producer: Paul Gulyas Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Claudio Corredor Sound: Brett Van Deusen Production Assistant: Ralphy Vasquez Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Paul Tael Movies & TV 'Jack Ryan' stars John Krasinski and Michael Kelly take the WIRED Autocomplete Interview and answer the internet's most searched questions about themselves. How many movies has John Krasinkski directed? Is John in every episode of The Office? Does Michael Kelly speak Spanish? Does he do audiobooks? Does Jack Ryan follow the books? Is it a real story? John and Michael answer all these questions and much more! Watch Tom Clancy’s Jack Ryan Season 3 now streaming on Prime Video Hashtag: #JackRyan Twitter: @JackRyanPV Instagram: @JackRyanPV Facebook: @JackRyanPV Director: Katherine Wzorek Director of Photography: Mark Rodgers Editor: Joshua Pullar Talent: John Krasinski, Michael Kelly Talent Booker: Tara Burke Line Producer: Joseph Buscemi Associate Producer: Brandon White Production Manager: Eric Martinez Production Coordinator: Fernando Davila Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Andy Morell Culture "People tend to do what they enjoy and not what they don't enjoy." Dr. Amanda Rebar, Associate Professor of Psychology, is here to help us make sense of New Year's resolutions. How does a resolution become a habit? Why are they so hard to stick to? How do we change our behaviors? Director: Maya Dangerfield Director of Photography: Brad Wickham Editor: Ron Douglas Expert: Dr. Amanda Rebar Line Producer: Joseph Buscemi Associate Producer: Samantha Vélez Production Manager: Eric Martinez Production Coordinator: Fernando Davila Camera Operator: Cloud Corredor Gaffer: Rebecca Van Der Meulen Audio: Brett Van Deusen Production Assistant: Rafael Vasquez Post Production Supervisor: Alexa Deutsch Post Production Coordinator: Ian Bryant Supervising Editor: Doug Larsen Assistant Editor: Diego Rentsch More

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/apples-deal-shows-ai-moving-devices/
### Query Relevance Score: 0.08829722553491592
### Highlights: None

Apple dropped $200 million this week on a company that makes lightweight artificial intelligence. It’s all about keeping an edge in AI ... by adding more AI to the edge. The acquisition of Xnor.ai, a Seattle startup working on low-power machine learning software and hardware, points to a key AI battleground for Apple and other tech heavyweights—packing ever-more intelligence into smartphones, smartwatches, and other smart devices that do computing on the “edge” rather that in the cloud. And doing it without killing your battery. “Machine learning is going to happen at the edge in a big way,” predicts Subhasish Mitra, a professor at Stanford who is working on low-power chips for AI. “The big question is how do you do it efficiently? That requires new hardware technology and design. And, at the same time, new algorithms as well.” The most powerful AI algorithms tend to be large and very power hungry when run on general purpose chips. But a growing number of startups, Xnor.ai among them, have begun devising ways to pare down AI models and run them on extremely energy-efficient, highly specialized hardware. Last March, Xnor.ai demoed a computer chip capable of running image recognition using only the power from a solar cell. A research paper authored by the founders of Xnor.ai and posted online in 2016 describes a more efficient form of convolutional neural network, a machine learning tool that is particularly well suited to visual tasks. The researchers reduced the size of the network by essentially creating a simplified approximation of the interplay among its layers. Apple already makes chips that perform certain AI tasks, like recognizing the wake phrase “Hey, Siri.” But its hardware will need to become more capable without draining your battery. Apple did not respond to a request for comment. Now, AI on the edge means running pretrained models that do a specific task, such as recognizing a face in a video or a voice in a call. But Mitra says it may not be long before we see edge devices that learn too. This could let a smartphone or another device improve its performance over time, without sending anything to the cloud. “That would be truly exciting,” he says. “Today most devices are essentially dumb.” Applying AI to video more efficiently, as Xnor.ai has demoed, will also be key for Apple, Google, and anyone working in mobile computing. Cameras and related software are a key selling point for iPhones and other smartphones, and video-heavy apps like TikTok are popular among younger smartphone customers. Edge computing has the added benefit of keeping personal data on your device, instead of sending it to the cloud. Dave Schubmehl, an analyst with the research firm IDC, says machine learning could also be used in Apple gadgets that currently don't include AI. "I can see them running AI on the Apple Watch and in AirPods, to clean up sound for example," he says. "There's tremendous opportunity in existing products." Running sophisticated AI on video, like an algorithm that can tell what’s happening in a scene or add complex special effects, is usually done in the cloud because it requires a significant amount of computer power. “For example, adding synthetic depth of field to your photos might require running a deep network to estimate the depth of each pixel,” says James Hays, a professor at Georgia Tech who specializes in computer vision. Besides making your iPhone’s camera smarter, Xnor.ai’s technology could help Apple in other areas. Giving machines more ability to perceive and understand the messy real world will be key to robotics, autonomous driving, and natural language understanding. “If the goal of AI is to achieve human-level intelligence, reasoning about images is vital to that,” Hays says, noting that roughly a third of the human brain is dedicated to visual processing. “Evolution seems to consider vision vital to intelligence,” he says. Apple seems to think that a more evolved form of computer vision is pretty valuable too. More Great WIRED Stories Inside the Feds’ battle against Huawei Here's what directing a Star Wars movie is really like Artificial intelligence makes bad medicine even worse How the extreme art of dropping stuff could upend physics Cities struggle to boost ridership with “Uber for transit” schemes 👁 The case for a light hand with AI. Plus, the latest news on artificial intelligence 📱 Torn between the latest phones? Never fear—check out our iPhone buying guide and favorite Android phones

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/27/mit-technology-review-amazons-alexa-devices-are-recording-your-life/
### Query Relevance Score: 0.06866918504238129
### Highlights: None

AP Photo/Charles Krupa The MIT Technology Review reported in 2018 that Amazon Alexa home assistant devices may actually be listening in on people’s daily lives even when not given commands. Despite such warnings, the e-commerce giant sold out of Alexa-powered devices before Christmas as their popularity continues to grow unabated. The MIT Technology Review reported in an article titled “Yes, Alexa is recording mundane details of your life, and it’s creepy as hell,” that Amazon Alexa home assistant devices are listening in on people’s conversations, a theory that has been around for some time but has never been confirmed. The MIT Technology Review reports: Beyond all the things I’ve clearly asked Alexa to do, in the past several months it has also tuned in, frequently several times a day, for no obvious reason. It’s heard me complain to my dad about something work-related, chide my toddler about eating dinner, and talk to my husband—the kinds of normal, everyday things you say at home when you think no one else is listening. And that’s precisely why it’s terrifying: this sort of mundane chitchat is my mundane chitchat. I invited Alexa into our living room to make it easier to listen to Pandora and occasionally check the weather, not to keep a log of intimate family details or record my kid saying “Mommy, we going car” and forward it to Amazon’s cloud storage. The MIT Technology Review notes that constant recording is one of the unfortunate downsides of home assistants that constantly listen for wake words such as “Alexa!” or “Hey, Siri!” Through 2019, Amazon faced continual bad news about its Alexa-powered devices on the subject of user privacy and security. Reports were published showing that Amazon employees and contractors located in India, Costa Rica, and Romania had ready access to users’ recordings and spent nine hours a day listening to the snippets. The work is mostly mundane. One worker in Boston said he mined accumulated voice data for specific utterances such as “Taylor Swift” and annotated them to indicate the searcher meant the musical artist. Occasionally the listeners pick up things Echo owners likely would rather stay private: a woman singing badly off key in the shower, say, or a child screaming for help. The teams use internal chat rooms to share files when they need help parsing a muddled word—or come across an amusing recording. This revelation led to a lawsuit against Amazon which claimed that Jeff Bezos’ Big Tech giant was breaking the law by recording children without their parent’s consent. In another threat to security, researchers in Tokyo documented that Amazon’s voice assistant hardware could be hacked with a $5 laser pointer. Despite the negativity about Amazon’s devices recording users when they don’t expect it, sales of Alexa-powered devices have continued to rise. Early in 2019, Amazon announced that it had sold 100 million Alexa devices. Sales haven’t slowed down since then. Although the company has not released Christmas sales figures, for the third quarter of 2019, it sold more than 10 million devices and enjoys a 36 percent share of the market. It’s next closest competitor, the Chinese company Alibaba, has a 13 percent market share. Breitbart News has previously published a guide explaining how to stop Amazon employees from having access to Alexa recordings, however, this does not stop the device from recording users’ daily interactions but rather protects them from being listened to by Amazon employees directly. Read the full guide here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/31/report-ai-algorithm-sent-first-warnings-about-chinas-coronavirus/
### Query Relevance Score: 0.0644695982336998
### Highlights: None

According to a recent report by Wired, a Canadian AI-driven algorithm called BlueDot sent the first warnings of the coronavirus outbreak in China beating both the CDC and the WHO. Wired reports that on January 6, the CDC issued a warning about a possible virus outbreak in China, the WHO made a similar announcement on January 9 after a number of pneumonia cases were reported in Wuhan. But both were beaten to the report by a Canadian AI health monitoring platform called BlueDot which sent warnings to customers on December 31, 2019. BlueDot uses an AI-driven algorithm to search through foreign-language news reports, animal and plant disease networks, and official statements from government bodies in order to warn its clients of danger zones such as Wuhan which has become the center of the coronavirus outbreak in China. Public health officials at the WHO and CDC are forced to rely on reports from Chinese officials — who are often not very forthcoming with information — but BlueDot relies on artificial intelligence that may prove faster than official statements. Kamran Khan, BlueDot’s founder and CEO, commented on the algorithm stating: “We know that governments may not be relied upon to provide information in a timely fashion. We can pick up news of possible outbreaks, little murmurs or forums or blogs of indications of some kind of unusual events going on.” Khan worked as a hospital infectious disease specialist in Toronto during the SARS epidemic of 2003 and commented on the current coronavirus situation stating: “There’s a bit of deja vu right now. In 2003, I watched the virus overwhelm the city and cripple the hospital. There was an enormous amount of mental and physical fatigue, and I thought, ‘Let’s not do this again.’” Khan launched BlueDot in 2014 and raised $9.4 million in venture capital funding, the firm now employees 40 people including physicians and programmers who have worked to develop the disease surveillance analytic program that uses natural language processing and machine learning techniques to sort through news reports in 65 languages as well as airline data and animal disease outbreak reports. “What we have done is use natural language processing and machine learning to train this engine to recognize whether this is an outbreak of anthrax in Mongolia versus a reunion of the heavy metal band Anthrax,” Kahn says. Read more about BlueDot at Wired here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/20/nyt-facial-recognition-startup-threatens-privacy-as-we-know-it/
### Query Relevance Score: 0.06187552958726883
### Highlights: None

The New York Times published an investigation recently into a little-known startup that helps law enforcement match photos of unknown people to their online images using facial recognition, and the privacy issues that are raised by the company and its massive database of photos. The New York Times writes in an article titled “The Secretive Company That Might End Privacy as We Know It” that a new tech startup that has been working with law enforcement could raise serious privacy issues for members of the public. Clearview AI, a facial recognition tech startup, has developed a system that allows users to upload a photo of a person to the app and see public photos of that person, along with links to where those photos appeared. The system scrapes information from Facebook, YouTube, Venmo and millions of other websites to help law enforcement track down individuals. The New York Times writes: Federal and state law enforcement officers said that while they had only limited knowledge of how Clearview works and who is behind it, they had used its app to help solve shoplifting, identity theft, credit card fraud, murder and child sexual exploitation cases. Until now, technology that readily identifies everyone based on his or her face has been taboo because of its radical erosion of privacy. Tech companies capable of releasing such a tool have refrained from doing so; in 2011, Google’s chairman at the time said it was the one technology the company had held back because it could be used “in a very bad way.” Some large cities, including San Francisco, have barred police from using facial recognition technology. The technology is reportedly being used by multiple law enforcement agencies amongst other groups, but many security experts have warned that the technology could easily be weaponized: “The weaponization possibilities of this are endless,” said Eric Goldman, co-director of the High Tech Law Institute at Santa Clara University. “Imagine a rogue law enforcement officer who wants to stalk potential romantic partners, or a foreign government using this to dig up secrets about people to blackmail them or throw them in jail.” The New York Times also notes that while investigating Clearview and finding little accurate public information about the company, Clearview began to investigate the Times reporter looking into the company: While the company was dodging me, it was also monitoring me. At my request, a number of police officers had run my photo through the Clearview app. They soon received phone calls from company representatives asking if they were talking to the media — a sign that Clearview has the ability and, in this case, the appetite to monitor whom law enforcement is searching for. Facial recognition technology has always been controversial. It makes people nervous about Big Brother. It has a tendency to deliver false matches for certain groups, like people of color. And some facial recognition products used by the police — including Clearview’s — haven’t been vetted by independent experts. Read more about Clearview and facial recognition technology at the New York Times here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/22/bokhari-leftists-are-learning-that-big-tech-already-has-a-social-credit-system/
### Query Relevance Score: 0.060726962983608246
### Highlights: None

More left-wing journalists are waking up to the fact that unaccountable Silicon Valley corporations are ranking Americans with a system that bears a growing resemblance to China’s totalitarian “social credit” system — almost a year after Breitbart Tech pointed out the same thing. China’s “social credit” system assigns citizens with a “score” based on good or bad behavior, which is in part determined by one’s compliance with Beijing’s totalitarian communist value system. Those who fall below a certain score are excluded from basic services. There’s no escape, either; to track everyone’s behavior, China subjects its citizens to mass surveillance, powered by a network of facial recognition cameras all across the country. Chinese citizens literally can’t escape their social credit score — low scores blocked 23 million Chinese citizens from traveling via train or airplane in less than one year, as reported by the Guardian. In an article for Engadget, left-wing writer Violet Blue notes that big tech companies have developed a system that is remarkably similar to China’s, ranking the behavior of users — and arbitrarily kicking them off their services — according to Silicon Valley’s own set of subjective values, including what it considers to be “conscientious” and “open” behavior. She takes particular aim at Airbnb: The Evening Standard reported on Airbnb’s patent for AI that crawls and scrapes everything it can find on you, “including social media for traits such as ‘conscientiousness and openness’ against the usual credit and identity checks and what it describes as ‘secure third-party databases’.” Blue makes the connection to China, where similarly invasive surveillance is used to build a profile and a social credit score on every citizen: The most famous social credit system in operation is that used by China’s government. It “monitors millions of individuals’ behavior (including social media and online shopping), determines how moral or immoral it is, and raises or lowers their “citizen score” accordingly,” reported Atlantic in 2018. … Trooly — nee Airbnb — is combining social credit scores with predictive policing. Tools like PredPol use AI that combines data points and historical events, factors like race and location, digital footprints and crime statistics, to predict likelihood of when and where crimes will occur (as well as victims and perpetrators). It’s no secret that predictive policing replicates and perpetuates discrimination. Last August, Fast Company made the same observation, pointing out that Silicon Valley’s combination of invasive surveillance with arbitrary user policies meant that “a parallel system” to China’s is being created in the United States. Breitbart News had, of course, made the connections months before they had. It’s almost as if conservatives were the first to feel the effects of big tech censorship! Blue is upset because the same methods that have been used to monitor and blacklist conservatives and right-wingers (many of whom have been kicked off Airbnb for political reasons) are now being used to ban prostitutes, a profession championed by the intersectional left. Combine this with companies like Instagram, Facebook, YouTube, and yes, Airbnb deciding what legal behaviors are acceptable for service, and now we’re looking at groups of historically marginalized people being denied involvement in mainstream economic, political, cultural and social activities — at scale. This week AP reported that Facebook and Instagram are doing exactly that. “Activists, sex therapists, abuse survivors, artists and sex educators,” are being unfairly censored by both services. “And it’s no small matter for them. Artists can be suddenly left without their audience, businesses without access to their customers and vulnerable people without a support network … it means that a company in Silicon Valley, whose online platforms have become not only our town squares but diaries, magazines, art galleries and protest platforms, gets final say on matters of free speech and self-expression.” Silicon Valley companies getting the final say on matters of free speech? Woah! Sound the alarms! Social media companies as the new town squares? That might be a groundbreaking argument, if PragerU hadn’t already made it three years ago. Unaccountable corporations, using their power to circumvent the democratic system and ban otherwise legal behavior? It’s only something Breitbart Tech has been talking about for one, two, three, let’s say four years at a conservative estimate. Given that Violet Blue takes issue with tech companies “deciding what legal behaviors are acceptable for service,” this means she will surely get behind political efforts to force social media companies to be strictly value-neutral in their approach to content. You know, like Rep. Louie Gohmert’s and Rep. Paul Gosar’s and Sen. Josh Hawley’s. It’s only a matter of time, right? Are you an insider at Google, Facebook, Twitter, or any other tech company who wants to confidentially reveal wrongdoing or political bias at your company? Reach out to Allum Bokhari at his secure email address allumbokhari@protonmail.com. Allum Bokhari is the senior technology correspondent at Breitbart News.

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/05/report-big-tech-will-expand-further-into-finance-in-2020/
### Query Relevance Score: 0.060044463723897934
### Highlights: None

JOSH EDELSON/Getty According to a recent report, the Masters of the Universe in Silicon Valley have plans to further expand into the world of finance in the new year — falling just short of opening their own banks. A recent report from CNBC claims that Silicon Valley tech giants are likely to expand their business into the world of finance even further in 2020, but many want to avoid the hassle of becoming a fully-fledged bank. With Facebook announcing its own cryptocurrency, Googles plans to introduce consumer bank accounts in collaboration with Citibank, and Apple’s new credit card in partnership with Goldman Sachs, finance seems to be a major focus for tech firms. CNBC writes: Though their products are different, both firms share something in common: they have no plans to become regulated financial institutions like Citi or Goldman. While Big Tech — a group of companies that includes Google, Amazon, Facebook and Apple — will undoubtedly push deeper into finance this year, their progress in banking will be “more of a slow creep than big strides,” said Sarah Kocianski, head of research at fintech consultancy 11:FS. “The big tech firms will continue to add services that are peripheral to banking to their existing offerings, without going full-stack banking,” she said. “The headache of getting, and maintaining, a banking license would likely be considered too big a risk for these companies. Instead, they will continue to operate with licensed partners.” But, Accenture’s global payments lead, Sulabh Agarwal stated when asked that it makes little sense for tech firms to become banks. “Do I expect them to become banks? I don’t think so do. I expect them to create new services to enhance their propositions,” Argawal stated. Facebook is making moves on two fronts in the world of finance, with its digital currency Libra and with its payment processing platform Facebook Pay. CNBC writes: “The theory goes that if 2 billion people were to withdraw their deposits from the banking system and move them into Libra tokens, you’d effectively have a run on the banks,” said Simon Taylor, co-founder and blockchain lead at 11:FS. “Facebook is absolutely big enough for that to be plausible, but whether or not it happens depends much more on what consumer problem is being solved.” Aside from libra, Facebook is also consolidating its payment products under a new brand called Facebook Pay. Uber, like its Southeast Asian competitor Grab, is moving further into finance with a division called Uber Money that houses a digital wallet and upgraded payment cards. They’ll face competition from the likes of Google Pay and Apple Pay in the U.S. and Chinese payment apps like Alipay and WeChat Pay. E-commerce giant Amazon is already in the process of lending out money but has yet to break into consumer banking. It should be noted that Amazon at one point set up a student loan scheme in 2016 with Wells Fargo which shut down shortly afterward. Sarah Kocianski, head of research at fintech consultancy 11:FS, stated that there was “every reason to suspect they’ve learned from that.” Read the full report at CNBC here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/29/what-is-our-meaning-in-life-in-a-world-of-technology/
### Query Relevance Score: 0.12129102647304535
### Highlights: None

The informal TechCrunch book club is now venturing into the short story “Exhalation,” the second piece in Ted Chiang’s eponymous collection. Today’s story gets at the meaning of existence, climate change, community and connection all within a beautifully intricate story that runs for just a few handfuls of pages. I was hooked, and so let’s talk about some of the messages Chiang wants to send as part of the piece. Some quick notes: Want to join the conversation? Feel free to email me your thoughts at bookclub@techcrunch.com or join some of the discussions on Reddit or Twitter (hashtag: #TCBookClub) Follow these informal book club articles here: https://techcrunch.com/book-review/. That page also has a built-in RSS feed for posts exclusively in the Book Review category, which is very low volume. Feel free to add your comments in our TechCrunch comments section below this post. Thoughts on “Exhalation” Chiang has constructed a magnificent story around the most basic and forgettable of substances: air. He starts the story with what otherwise appears to be a normal day in the life of an everyday human, but within a few paragraphs, we learn that the narrator is “going to the filling stations” and it slowly dawns on us that the narrator — and all the people that populate this imaginative world — are actually some form of cybernetic beings, dependent on a mechanical supply of air for their machined bodies. We learn that these filling stations, where people pick up their air supply, aren’t just refueling utilities, but are key community outposts where connections are formed between people. “For the filling stations are the primary venue for social conversation, the places from which we draw emotional sustenance as well as physical.” But that’s not all, Chiang writes. “… there is camaraderie derived from the awareness that all our air comes from the same source…” As we learn as the story progresses, air isn’t just present in this universe — it is fundamentally the connective substance not only between every individual, but also the past and the future. Memories held in the brains of these individuals aren’t inscribed, but are rather reconfigured as air passes through them. Therefore, what is memorable — what is most visible — is ultimately a function of what is not even seen. The narrator describes this discovery as he investigates his own brain in an experiment: Watching the oscillations of these flakes of gold, I saw that air does not, as we had always assumed, simply provide power to the engine that realizes our thoughts. Air is in fact the very medium of our thoughts. All that we are is a pattern of air flow. What’s incredible about this story is that Chiang pushes this metaphor another layer deeper. The narrator learns that the world relies on the pressure difference between the air in the atmosphere and the air in each individual’s body, and that this difference is decreasing. Suddenly, the fate of the entire universe has become clear: There may well be air everywhere, but it’s the differential that matters, and that differential is slowly receding with every breath, every twitch of a limb and stray thought. Equilibrium — and therefore death — is just around the corner. Gloriously, Chiang describes the dawn of time: The universe began as an enormous breath being held. Who knows why, but whatever the reason, I am glad that it did, because I owe my existence to that fact. All my desires and ruminations are no more and no less than eddy currents generated by the gradual exhalation of our universe. And until this great exhalation is finished, my thoughts live on. This is an ambitious leap and one that springs beautifully from the page. We have gone from air as individual sustenance, to air as community resource and connective tissue, to air as the very meaning of existence, tied into a fate where we already know how the final chapter will be written. Here is the substance we never think about, and instead of being nothing it is actually everything we care about. There is a parallel here of course to our own world. In much the way the everyday actions of the individuals in this short story deplete the pressure difference of their world and ultimately make it uninhabitable, there is clearly a connection to our own present crisis regarding climate change. How should we handle the fatalism of those climate trendlines that show Earth eventually dying off sometime in the future? The story doesn’t try to minimize that fatalism. In fact, it actively diminishes the idea that there are technical solutions to these problems. Our narrator describes a sect known as the “Reversalists,” who attempt to build a machine that can increase the difference in air pressure in the universe. But our narrator isn’t optimistic, and essentially argues that such a machine is impossible to design. Instead, the story exhorts us to revel in the limited time we have in this universe, even knowing that the world is going to come to an inevitable end. “Because even if a universe’s life span is calculable, the variety of life that is generated within it is not.” Rather than spending our limited time trying to push back the end (of the universe or of our own demise), we should instead ignore that fatal ending and focus on the present, and the wonders that we get to experience while the world is alive for us. I can go on and on about air here, and indeed, multiple re-readings of this chapter have revealed new connections and symbols that are absolutely fascinating. But I want to move on to two other points that I think this short story wants to tell. In the story, our narrator is an anatomist, who learns about a strange set of facts — that clocks appear to be changing speed in multiple districts in this universe. They learn about these facts, but unlike anyone else, they seem willing to ask more fundamental and deeper questions about why basic mechanics of the universe aren’t what they seem: Most people suspected fraud, a practical joke perpetrated by mischief-makers. I had a different suspicion, a darker one that I dared not voice, but it decided my course of action; I would proceed with my experiment. Our narrator explains that there is a reigning theory about the workings of the brain called the inscription hypothesis, which they reject. By the end of the story though, we see how our narrator’s experiment of opening their own brain and investigating its workings eventually overturned that hypothesis. It’s not only a commentary on the scientific method, but I also feel that there is a point here about asking even the hardest questions about the data that we are seeing in our universe. We talk about this all the time in the startup world, but here we have in clear relief a person who didn’t just accept the prevailing theory of how something worked, or ignored the facts and data from their universe, or avoided approaching the hardest questions they stumbled upon. Instead, they confronted them, and also did so individually, without the consent or approval of others. That’s a reminder that sometimes, when we are on the frontiers of science, that the hardest questions sometimes can’t be answered in collaboration with others — that the air that connects us breaks down here. The other symbol I loved here is around the “experiment” itself. Our narrator builds a machine that allows them to dissect their own brain, and in the process allows them to see the true meaning of the universe. Chiang spends a sizable part of the story building up the dissection, going through with it and discussing its implications, and it isn’t hard to see why. The brain dissection is a beautiful metaphor for literally “opening our minds” to new experiences and ideas. Our narrator carefully prepares to open their mind, splaying their brain out in a painstaking and careful order to understand its inner workings. As they do this though, they discover who they really are, and also the fate of the universe along the way. It’s a gorgeous symbol, and like so much of this story, a layered opinion about what it means to be an individual and how we relate to each other. As Chiang closes out, “Contemplate the marvel that is existence, and rejoice that you are able to do so. I feel I have the right to tell you this because, as I am inscribing these words, I am doing the same.” Some questions for “What’s Expected of Us” Next week, we will read the ultra-short story (four pages!), the third part of “Exhalation” the collection. It’s an interesting meditation on free will versus destiny, and asks a lot of questions in a taut story. Have comments on what you read? Send them to me at bookclub@techcrunch.com

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/30/business/artificial-intelligence-robots-retail.html
### Query Relevance Score: 0.1514386236667633
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times News subscription; current subscribers not eligible. Subscription excludes print edition. Subscription also excludes digital access to New York Times Games, Cooking, Wirecutter or The Athletic. Your payment method will automatically be charged in advance the introductory rate of $4 every 4 weeks for 1 year, and after 1 year the standard rate of $17 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war.print
### Query Relevance Score: 0.08723042160272598
### Highlights: None

By , Kris Osborn Published January 06, 2020 File photo - A 10th Mountain Division Soldier fires an M4 rifle during a platoon Situational Training Exercise at a range in Arta, Djibouti, Aug. 25, 2018. (U.S. Air Force photo by Senior Airman Haley D. Phillips) Targets emerge in seconds, incoming enemy fire puts lives at risk and shifting combat dynamics require immediate, on-the-spot decisions in a matter of seconds -- all as soldiers navigate the complex web of threats during all-out, high-risk ground-warfare. These kinds of predicaments, which characterize much of what soldiers train to face, are immeasurably improved by emerging applications of AI; artificial intelligence can already gather, fuse, organize and analyze otherwise disparate pools of combat-sensitive data for individual soldiers. Target information from night vision sensors, weapons sights, navigational devices and enemy fire detection systems can increasingly be gathered and organized for individual human soldier decision-makers. However, what comes after this? Where will AI go next in terms of changing modern warfare for Army infantry on the move in war? The Army Research Laboratory is now immersed in a complex new series of research and experimentation initiatives to explore a “next-level” of AI. Fundamentally, this means not only using advanced algorithms to ease the cognitive burden for individual soldiers -- but also network and integrate otherwise stovepiped applications of AI systems. In effect, this could be described as performing AI-enabled analytics on groups of AI systems themselves. “Autonomy is doing things in a snipped way that can be connected. We can benefit from an overarching AI approach, something that looks at the entire mission. Right now our autonomy solves very discreet problems that are getting more complicated,” J. Corde Lane, Ph.D., director, Human Research and Engineering, CCDC-Army Research Laboratory, told Warrior in an interview. F-35 SET FOR LASER BOOST What does this mean? In essence, it translates into a way combat commanders will not only receive AI-generated input from individual soldiers but also be able to assess how different AI systems can themselves be compared to one another and analyzed as a dynamic group. For instance, Lane explained, perhaps multiple soldier-centric AI-empowered assessments can be collected and analyzed in relation to one another with a mind to how they impact a broader, squad-level combat dynamic. In particular, simultaneous analysis of multiple soldier-oriented AI system can help determine the best course of action for an entire unit, in relation to an overall mission objective. “What is the entire mission and possible courses of action? Do we optimize the logistics flow? Find targets as the dynamic battlefield gets more complex? The Commander can draw upon advanced AI to explore new options,” Lane explained. Therefore, in addition to drawing upon algorithms able to organize data within a given individual system, future AI will encompass using real-time analytics to assess multiple systems simultaneously and how they impact one another to offer an overall integrated view. All of this progress, just as is the case now, will still rely heavily upon human decision-making faculties to optimize its added value for combat. Integrating a collective picture, drawing upon a greater range of variables will require soldiers to incorporate new tactics and methods of analysis to best leverage the additional available information. SOLDIERS USE AI TO FIRE PRECISION GRENADES, GUIDE DRONE ATTACKS “When we have new and improved autonomy coming in, soldiers need to know how to use that. How do you keep the soldier always at the center and adapt to them as you adapt to the new AI?” Lane asked. Perhaps one soldier receives organized sensor-driven targeting data relevant to a specific swath of terrain, while another AI system is organizing variables to determine the supply flow of ammunition, fuel or other logistical factors. “Data never seen cannot be learned. It is not about AI, but combining AI with a soldier who has the concept of an entire mission. AI provides information and then they get put together. When you are under fire, you are going to need different types of information,” Lane explained. For example, comparing and analyzing various AI systems to help engender a collective picture of some kind might enable a commander to know “if you go this way you will use more fuel but it will be safer,” as Lane explained. HOW AI CHANGES ATTACK MISSIONS FOR US FIGHTER JETS AND BOMBERS Interestingly, Lane’s point about the irreplaceable characteristics of human cognition in the face of new AI-driven technologies is anticipated in a 2017 essay from the Chatham House Royal Institute of International Affairs, called “Artificial Intelligence and the Future of War.” The essay, written by M.L. Cummings, states that “replicating the intangible concept of intuition, knowledge-based reasoning and true expertise is, for now, beyond the realm of computers.” Mathematically oriented computer algorithms naturally face limitations when it comes to things like judgments, feelings or quickly assessing not-yet-seen information; an AI-database can only be as effective as the information it already has stored in its database. While Machine-Learning techniques continue to accelerate the pace at which an existing AI database can quickly integrate and perform analytics on new information, AI-infused computing can only make decisions or solve problems in relation to the information it already has stored. Now it goes without saying that these databases are increasingly vast, almost seeming limitless, yet they do need to consistently be fed with not-yet-stored information of great relevance to wartime decisions. CLICK HERE TO GET THE FOX NEWS APP The Chatham House essay puts it this way: “Every autonomous system that interacts in a dynamic environment must construct a world model and continually update that model. This means that the world must be perceived (or sensed through cameras, microphones and/or tactile sensors) and then reconstructed in such a way that the computer ‘brain’ has an effective and updated model of the world it is in before it can make decisions. The fidelity of the world model and the timeliness of its updates are the keys to an effective autonomous system.” (Artificial Intelligence and the Future of War” M.L. Cummings) URL https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/heres-what-the-world-will-look-like-in-2030-right/
### Query Relevance Score: 0.1281799077987671
### Highlights: None

Predicting the future is hard, but that doesn't stop people from trying—especially people named Elon Musk. As he well knows, being bold is pretty much the only way thought castles can become concrete (or wood, brick, or metal). In this list, WIRED has gathered a handful of far-reaching goals as a framework for what to expect in the decade ahead. Space colonies. A mega-expansion in genome sequencing. Sweet little nuclear power plants. It's never too early to start holding the promise-makers responsible for their claims. After all, even a bajillionaire needs an accountability buddy. Welcome to the Moon Base When the last person left the moon in 1972, few could have predicted that humans wouldn’t return for another 50 years. But NASA says this time around things will be different. The agency is planning a crewed mission to the moon in 2024, and this time it wants to stick around. The idea of the Artemis mission is to lay the foundation for a permanent human presence on and around the moon, which will then serve as a jump-off point for the agency’s journey to Mars. When Artemis was first announced, it was easy to be incredulous: The agency wants to use a rocket that hasn’t flown yet, it lacks the necessary funds for a moon mission ... the list goes on. But this year NASA has made big strides on the mission. The agency has selected a handful of companies to build components for its lunar gateway, a space station that will be in orbit around the moon, and it has solicited designs for a lunar lander. If NASA does hit its 2024 target for a crewed mission to the moon, it’s not so crazy to think it might have a permanent moon base by 2030. —Daniel Oberhaus Climate Apocalypse Now In October 2018 the UN warned that humanity has 12 years left to avoid catastrophic climate change. That means that by 2030, we’ll need to cut global greenhouse gas emissions in half, not so much a tall order as a towering one, given that emissions are still rising year to year. In fairness, the world won’t suddenly end on January 1, 2030, if we don’t meet that goal. But the report is spot-on in its mantra: The faster we switch to a world economy run on renewable energy, the better we can attenuate the consequences—stronger storms, rising seas, fiercer wildfires. So what can we do? For one, we need carbon taxes the world over: Release greenhouse gases and you pay a fee, which incentivizes the adoption of green energy. We have to massively subsidize solar panels and electric cars. We have to bolster public transportation and redesign cities to discourage the use of cars. And this may sound niche, but it’s hugely important: AC units need a fundamental redesign to be more efficient or even sequester CO2, as demand for them soars in lockstep with global temperatures. —Matt Simon Genomic Mega Millions If you think you’re currently living in the age of Big DNA, think again. The next decade will see a more than hundredfold boom in the world’s output of human genetic data. The drop in sequencing costs is shifting DNA testing out of the research lab and into mainstream medical practice. Population-based sequencing projects in more than a dozen countries, including the US, are expected to produce 60 million genomes by 2025. By 2030, China hopes to add another 100 million from its own precision medicine initiative. The impact is hard to even imagine. To date, only about a million people have had their whole genomes sequenced. And it’s not a very diverse cohort. More data from all over the globe will allow for more powerful, fine-grained analyses of how genes shape health and behavior. Very large genetic data sets are ideal for a new technique called Mendelian randomization, which mimics clinical trials, allowing researchers to tease apart causes and correlations. Bigger samples will also make it possible to forecast even complex traits—like height or susceptibility to heart disease—from DNA. A world so saturated with genetic data will come with its own risks. The emergence of genetic surveillance states and the end of genetic privacy loom. Technical advances in encrypting genomes may help ameliorate some of those threats. But new laws will need to keep the risks and benefits of so much genetic knowledge in balance. —Megan Molteni Teeny Tiny Nuclear Power Plants By 2030, the Vogtle power plant in Georgia, the only nuclear power station currently under construction in the US, will have been running for a few years. It's likely to be the decade's only new large-scale nuclear power plant to come online, but that doesn’t mean the United States is abandoning fission energy. Instead, expect to see small nuclear reactors start popping up. Just a fraction of the size of a typical nuclear reactor, these advanced ones can be mass-produced and easily shipped anywhere in the country, no matter how remote. The first small reactors, developed by a company called NuScale Power, should start splitting atoms at Idaho National Laboratories in 2026. The Department of Energy is also working to get even smaller reactors, known as microreactors, churning out electrons at a federal facility by 2027. Nuclear energy gets a bad rap in some American environmental circles and it’s not hard to see why. The meltdown at Three Mile Island and the decades-long debate about storing nuclear waste at Yucca Mountain have made people skittish about the prospects of this carbon-free energy source, but the UN and many experts say fission energy will be key to hitting our climate goals. The world needs to halve its carbon emissions by 2030, and embracing the new generation of nuclear reactors may be key to making that happen. —Daniel Oberhaus Elon Musk's Plan for Mars Sending life to Mars has been Elon Musk’s goal from day one, and this is the decade he has pegged for his touchdown on the red planet. Originally, he wanted to ship off some plants in a greenhouse, but as SpaceX came to dominate the new space industry, Musk’s ambitions have risen in tandem to include a full-fledged Mars colony. In 2019 he showed off, for the first time, the rocket that could make that happen. Musk’s Mars timeline is predictably slippery. In 2017 he predicted SpaceX would send a cargo mission to Mars by 2022. The following year, he said the first crewed mission to Mars would happen in seven to ten years, or no later than 2028. Musk is notorious for wildly underestimating the amount of time it takes to accomplish his ambitious goals, so don't schedule your launch parties just yet. Still, he tends to follow through on his promises—eventually. —Daniel Oberhaus Goodbye, Poverty! Predictions for the future often have a sci-fi bent: jet packs, flying cars, brain-computer hybrids. The United Nations is supposed to stick to more solid ground, but some of its Sustainable Development Goals for 2030 sound nearly as fantastical. In a mere 10 years, the UN plans to eradicate poverty “in all its forms everywhere.” No big deal. The UN already declared October 17 International Poverty Eradication Day. But elevating the lives of those subsisting on less than $1.25 a day will take a little more. The good news is that crushing global poverty has declined significantly: The World Bank reports that 1.1 billion fewer people live in extreme poverty than did in 1990. The organization has been working with countries to improve education, gender equality, food security, social services, and more. But the gains are unevenly distributed, and climate change now threatens to undo much of the progress, pushing millions back into destitution and creating a “climate apartheid.” This is already happening in Central America and Africa, where drought has caused millions to leave their homes. The prospect of ending poverty seems, well, poor. But let's face it, the future is unknowable. The 1900 edition of Ladies’ Home Journal predicted that, within the century, pneumatic tubes would deliver goods to homes and the letters C, X, and Q would drop out of the alphabet. Yet it also foresaw the mobile phone and color photography. Strong science coupled with political will might yet turn climate change around, and transform the UN’s predictions from a dream into reality. —Sara Harrison More Great WIRED Stories Instagram, my daughter, and me Tweak these Google Chrome settings to level up your browsing Welcome to Rachel, Nevada—the town closest to Area 51 The Irishman gets de-aging right—no tracking dots necessary Ewoks are the most tactically advanced fighting force in Star Wars 👁 Will AI as a field "hit the wall" soon? Plus, the latest news on artificial intelligence 🎧 Things not sounding right? Check out our favorite wireless headphones, soundbars, and Bluetooth speakers

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/31/report-ai-algorithm-sent-first-warnings-about-chinas-coronavirus/
### Query Relevance Score: 0.09147537499666214
### Highlights: None

According to a recent report by Wired, a Canadian AI-driven algorithm called BlueDot sent the first warnings of the coronavirus outbreak in China beating both the CDC and the WHO. Wired reports that on January 6, the CDC issued a warning about a possible virus outbreak in China, the WHO made a similar announcement on January 9 after a number of pneumonia cases were reported in Wuhan. But both were beaten to the report by a Canadian AI health monitoring platform called BlueDot which sent warnings to customers on December 31, 2019. BlueDot uses an AI-driven algorithm to search through foreign-language news reports, animal and plant disease networks, and official statements from government bodies in order to warn its clients of danger zones such as Wuhan which has become the center of the coronavirus outbreak in China. Public health officials at the WHO and CDC are forced to rely on reports from Chinese officials — who are often not very forthcoming with information — but BlueDot relies on artificial intelligence that may prove faster than official statements. Kamran Khan, BlueDot’s founder and CEO, commented on the algorithm stating: “We know that governments may not be relied upon to provide information in a timely fashion. We can pick up news of possible outbreaks, little murmurs or forums or blogs of indications of some kind of unusual events going on.” Khan worked as a hospital infectious disease specialist in Toronto during the SARS epidemic of 2003 and commented on the current coronavirus situation stating: “There’s a bit of deja vu right now. In 2003, I watched the virus overwhelm the city and cripple the hospital. There was an enormous amount of mental and physical fatigue, and I thought, ‘Let’s not do this again.’” Khan launched BlueDot in 2014 and raised $9.4 million in venture capital funding, the firm now employees 40 people including physicians and programmers who have worked to develop the disease surveillance analytic program that uses natural language processing and machine learning techniques to sort through news reports in 65 languages as well as airline data and animal disease outbreak reports. “What we have done is use natural language processing and machine learning to train this engine to recognize whether this is an outbreak of anthrax in Mongolia versus a reunion of the heavy metal band Anthrax,” Kahn says. Read more about BlueDot at Wired here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/29/what-is-our-meaning-in-life-in-a-world-of-technology/
### Query Relevance Score: 0.1369898021221161
### Highlights: None

The informal TechCrunch book club is now venturing into the short story “Exhalation,” the second piece in Ted Chiang’s eponymous collection. Today’s story gets at the meaning of existence, climate change, community and connection all within a beautifully intricate story that runs for just a few handfuls of pages. I was hooked, and so let’s talk about some of the messages Chiang wants to send as part of the piece. Some quick notes: Want to join the conversation? Feel free to email me your thoughts at bookclub@techcrunch.com or join some of the discussions on Reddit or Twitter (hashtag: #TCBookClub) Follow these informal book club articles here: https://techcrunch.com/book-review/. That page also has a built-in RSS feed for posts exclusively in the Book Review category, which is very low volume. Feel free to add your comments in our TechCrunch comments section below this post. Thoughts on “Exhalation” Chiang has constructed a magnificent story around the most basic and forgettable of substances: air. He starts the story with what otherwise appears to be a normal day in the life of an everyday human, but within a few paragraphs, we learn that the narrator is “going to the filling stations” and it slowly dawns on us that the narrator — and all the people that populate this imaginative world — are actually some form of cybernetic beings, dependent on a mechanical supply of air for their machined bodies. We learn that these filling stations, where people pick up their air supply, aren’t just refueling utilities, but are key community outposts where connections are formed between people. “For the filling stations are the primary venue for social conversation, the places from which we draw emotional sustenance as well as physical.” But that’s not all, Chiang writes. “… there is camaraderie derived from the awareness that all our air comes from the same source…” As we learn as the story progresses, air isn’t just present in this universe — it is fundamentally the connective substance not only between every individual, but also the past and the future. Memories held in the brains of these individuals aren’t inscribed, but are rather reconfigured as air passes through them. Therefore, what is memorable — what is most visible — is ultimately a function of what is not even seen. The narrator describes this discovery as he investigates his own brain in an experiment: Watching the oscillations of these flakes of gold, I saw that air does not, as we had always assumed, simply provide power to the engine that realizes our thoughts. Air is in fact the very medium of our thoughts. All that we are is a pattern of air flow. What’s incredible about this story is that Chiang pushes this metaphor another layer deeper. The narrator learns that the world relies on the pressure difference between the air in the atmosphere and the air in each individual’s body, and that this difference is decreasing. Suddenly, the fate of the entire universe has become clear: There may well be air everywhere, but it’s the differential that matters, and that differential is slowly receding with every breath, every twitch of a limb and stray thought. Equilibrium — and therefore death — is just around the corner. Gloriously, Chiang describes the dawn of time: The universe began as an enormous breath being held. Who knows why, but whatever the reason, I am glad that it did, because I owe my existence to that fact. All my desires and ruminations are no more and no less than eddy currents generated by the gradual exhalation of our universe. And until this great exhalation is finished, my thoughts live on. This is an ambitious leap and one that springs beautifully from the page. We have gone from air as individual sustenance, to air as community resource and connective tissue, to air as the very meaning of existence, tied into a fate where we already know how the final chapter will be written. Here is the substance we never think about, and instead of being nothing it is actually everything we care about. There is a parallel here of course to our own world. In much the way the everyday actions of the individuals in this short story deplete the pressure difference of their world and ultimately make it uninhabitable, there is clearly a connection to our own present crisis regarding climate change. How should we handle the fatalism of those climate trendlines that show Earth eventually dying off sometime in the future? The story doesn’t try to minimize that fatalism. In fact, it actively diminishes the idea that there are technical solutions to these problems. Our narrator describes a sect known as the “Reversalists,” who attempt to build a machine that can increase the difference in air pressure in the universe. But our narrator isn’t optimistic, and essentially argues that such a machine is impossible to design. Instead, the story exhorts us to revel in the limited time we have in this universe, even knowing that the world is going to come to an inevitable end. “Because even if a universe’s life span is calculable, the variety of life that is generated within it is not.” Rather than spending our limited time trying to push back the end (of the universe or of our own demise), we should instead ignore that fatal ending and focus on the present, and the wonders that we get to experience while the world is alive for us. I can go on and on about air here, and indeed, multiple re-readings of this chapter have revealed new connections and symbols that are absolutely fascinating. But I want to move on to two other points that I think this short story wants to tell. In the story, our narrator is an anatomist, who learns about a strange set of facts — that clocks appear to be changing speed in multiple districts in this universe. They learn about these facts, but unlike anyone else, they seem willing to ask more fundamental and deeper questions about why basic mechanics of the universe aren’t what they seem: Most people suspected fraud, a practical joke perpetrated by mischief-makers. I had a different suspicion, a darker one that I dared not voice, but it decided my course of action; I would proceed with my experiment. Our narrator explains that there is a reigning theory about the workings of the brain called the inscription hypothesis, which they reject. By the end of the story though, we see how our narrator’s experiment of opening their own brain and investigating its workings eventually overturned that hypothesis. It’s not only a commentary on the scientific method, but I also feel that there is a point here about asking even the hardest questions about the data that we are seeing in our universe. We talk about this all the time in the startup world, but here we have in clear relief a person who didn’t just accept the prevailing theory of how something worked, or ignored the facts and data from their universe, or avoided approaching the hardest questions they stumbled upon. Instead, they confronted them, and also did so individually, without the consent or approval of others. That’s a reminder that sometimes, when we are on the frontiers of science, that the hardest questions sometimes can’t be answered in collaboration with others — that the air that connects us breaks down here. The other symbol I loved here is around the “experiment” itself. Our narrator builds a machine that allows them to dissect their own brain, and in the process allows them to see the true meaning of the universe. Chiang spends a sizable part of the story building up the dissection, going through with it and discussing its implications, and it isn’t hard to see why. The brain dissection is a beautiful metaphor for literally “opening our minds” to new experiences and ideas. Our narrator carefully prepares to open their mind, splaying their brain out in a painstaking and careful order to understand its inner workings. As they do this though, they discover who they really are, and also the fate of the universe along the way. It’s a gorgeous symbol, and like so much of this story, a layered opinion about what it means to be an individual and how we relate to each other. As Chiang closes out, “Contemplate the marvel that is existence, and rejoice that you are able to do so. I feel I have the right to tell you this because, as I am inscribing these words, I am doing the same.” Some questions for “What’s Expected of Us” Next week, we will read the ultra-short story (four pages!), the third part of “Exhalation” the collection. It’s an interesting meditation on free will versus destiny, and asks a lot of questions in a taut story. Have comments on what you read? Send them to me at bookclub@techcrunch.com

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/26/technology-is-anthropology/
### Query Relevance Score: 0.12795934081077576
### Highlights: None

The interesting thing about the technology business is that, most of the time, it’s not the technology that matters. What matters is how people react to it, and what new social norms they form. This is especially true in today’s era, well past the midpoint of the deployment age of smartphones and the internet. People — smart, thoughtful people, with relevant backgrounds and domain knowledge — thought that Airbnb and Uber were doomed to failure, because obviously no one would want to stay in a stranger’s home or ride in a stranger’s car. People thought the iPhone would flop, because users would “detest the touch screen interface.” People thought enterprise software-as-a-service would never fly, because executives would insist on keeping servers in-house at all costs. These people were so, so, so wrong; but note that they weren’t wrong about the technology. (Nobody really argued about the technology.) Instead they were dead wrong about other people, and how their own society and culture would respond to this new stimulus. They were anthropologically incorrect. This, of course, is why every major VC firm, and every large tech company, keeps a crack team of elite anthropologists busy at all times, with big budgets and carte blanche, reporting directly to the leadership team, right? (Looks around.) Oh. Instead they’re doing focus groups and user interviews, asking people in deeply artificial settings to project their usage of an alien technology in an unknown context, and calling that their anthropological, I’m sorry, their market research? Oh. I kid, I kid. Sort of, at least, in that I’m not sure a crack team of elite anthropologists would be all that much more effective. It’s hard enough getting an accurate answer of how a person would use a new technology when that’s the only variable. When they live in a constantly shifting and evolving world of other new technologies, when the ones which take root and spread have a positive-feedback-loop effect on the culture and mindset toward new technologies, and when every one of your first 20 interactions with new tech changes your feelings about it … it’s basically impossible. And so: painful trial and error, on all sides. Uber and Lyft didn’t think people would happily ride in strangers’ cars either; that’s why Uber started as what is now Uber Black, basically limos-via-app, and Lyft used to have that painfully cringeworthy “ride in the front seat, fist-bump your driver” policy. Those are the success stories. The graveyard of companies whose anthropological guesses were too wrong to pivot to rightness, or who couldn’t / wouldn’t do so fast enough, is full to bursting with tombstones. That’s why VCs and Y Combinator have been much more secure businesses than startups; they get to run dozens or hundreds of anthropological experiments in parallel, while startups get to run one, maybe two, three if they’re really fast and flexible, and then they die. This applies to enterprise businesses too, of course. Zoom was an anthropological bet that corporate cultures would make video conferencing big and successful if it actually worked. It’s easy to imagine the mood among CEOs instead being “we need in-person meetings to encourage those Moments of Serendipity,” which you’ll notice is the same argument that biased so many big companies against remote work and in favor of huge corporate campuses … an attitude that looks quaint, old-fashioned and outmoded, now. This doesn’t just apply to the deployment phase of technologies. The irruption phase has its own anthropology. But irruption affects smaller sectors of the economy, whose participants are mostly technologists themselves, so it’s more anthropologically reasonable for techies to extrapolate from their own views and project how that society will change. The meta-anthropological theory held by many is that what the highly technical do today, the less technical will do tomorrow. That’s a belief held throughout the tiny, wildly non-representative cryptocurrency community, for instance. But even if it was true once, is it still? Or is a shift away from that pattern to another, larger social change? I don’t know, but I can tell you how we’re going to find out: painful trial and error.

---

## Article published: 01/2020
### Source URL: https://techcrunch.com/2020/01/17/deep-tech-vcs-on-what-they-view-as-some-of-the-most-impactful-young-startups-right-now/
### Query Relevance Score: 0.12458433210849762
### Highlights: None

During this week’s Democratic debate, there was a lot of talk, unsurprisingly, about ensuring the future of this country’s children and grandchildren. Climate change was of particular interest to billionaire Tom Steyer, who said repeatedly that addressing it would be his top priority were he elected U.S. president. As it happens, earlier the same day, we’d spent time on the phone with two venture capitalists who think of almost nothing else every day. The reason: they both invest in so-called deep tech, and they meet routinely with startups whose central focus is on making the world habitable for generations of people to come — as well as trying to produce outsize financial returns, of course. The two VCs with whom we talked know each other well. Siraj Khaliq is a partner at the global venture firm Atomico, where he tries to find world-changing startups that are enabled by machine learning, AI, and computer vision. He has strong experience in the area, having cofounded The Climate Corporation back in 2006, a company that helps farmers optimize crop yield and that was acquired by Monsanto in 2013 for roughly $1 billion. Seth Bannon is meanwhile a founding partner of Fifty Years, a nearly five-year-old, San Francisco-based seed-stage fund whose stated ambition is backing founders who want to solve the world’s biggest problems. The investors’ interests overlap so much that Khaliq is also one of Fifty Years’s investors. From both, we wanted to know which companies or trends are capturing their imagination and, in some cases, their investment dollars. Following are excerpts from our extended conversation earlier this week. (We thought it was interesting; hopefully you will, too.) TC: Seth, how would you describe what you’re looking to fund at your firm? SB: There’s a Winston Churchill essay [penned nearly 100 years ago] called “Fifty Years Hence” that describes what we do. He predicts genomic engineering, synthetic biology, growing meat without animals, nuclear power, satellite telephony. Churchill also notes that because tech changes so quickly that it’s important that technologists take a principled approach to their work. [Inspired by him] we’re backing founders who can make a ton of money while doing good and focusing on health, disease, the climate crisis . . . TC: What does that mean exactly? Are you investing in software? SB: We’re not so enthusiastic about pure software because it’s been so abstracted away that it’s become a commodity. High school students can now build an app, which is great, but it also means that competitive pressures are very high. There are a thousand funds focused on software seed investing. Fortunately, you can now launch a synthetic biology startup with seed funding, and that wasn’t possible 10 years ago. There are a lot of infrastructural advancements happening that makes [deep tech investing even with smaller checks] interesting. TC: Siraj, you also invest exclusively on frontier, or deep tech, at Atomico. What’s your approach to funding startups? SK: We do Series A [deals] onward and don’t do seed stage. We primarily focus on Europe. But there’s lot of common thinking between us and Seth. As a fund, we’re looking for big problems that change the world, sometimes at companies that won’t necessarily be big in five years but if you look out 10 years could be necessary for humanity. So we’re trying to anticipate all of these big trends and focus on three or four theses a year and talk as much as we can with academics and other experts to understand what’s going on. Founders then know we have an informed view. Last year, we focused on synthetic biology, which is a becoming so broad a category that it’s time to start subdividing it. We were also doing AI-based drug discovery and quantum computing and we started to spend some time on energy as well. We also [continued an earlier focus on ] the future of manufacturing and industry. We see a number of trends that make [the latter] attractive, especially in Europe where manufacturing hasn’t yet been digitized. TC: Seth, you mentioned synthetic biology infrastructure. Can you elaborate on what you’re seeing that’s interesting on this front? SB: You’ve maybe heard of directed evolution, technology that allows biologists to use the power of evolution to get microbes or other biological machines to do what they want them to do that would have been impossible before. [Editor’s note: here, Bannon talks a bit about Frances Arnold, the Nobel Prize-winning chemist who was awarded the honor in 2018 for developing the technique.] So we’re excited to back [related] startups. One, Solugen, enzymatically makes industrial chemicals [by combining genetically modified enzymes with organic compounds, like plant sugars]. Hydrogen peroxide is a $6 billion dollar industry, and it’s currently made through a petroleum-based process in seven-football-field-long production plants that sometimes explode and kill people. TC: Is this then akin to Zymergen, which develops molecules in order to create unique specialty materials? SB: Zymergen mainly works as a kind of consultant to help companies engineer strains that they want. Solugen is a vertically integrated chemicals company, so it [creates its formulations], then sells directly into industry. TC: How does this relate to new architectures? SB: The way to think about it is that there’s a bunch of application-level companies, but as synthetic biology companies start to take off, there’s a bunch of emerging infrastructure layer companies. One of these is Ansa Biotechnologies, which has a fully enzymatic process for writing DNA. Like Twist, which went public, they make DNA to sell to customers in the biotech industry. But whereas Twist is using a chemical process to make DNA, Ansa’s approach is fully enzymatic. [Editor’s note: More on the competition in this emerging space here.] Also, if you look at plant-based alternatives to meat, they’re more sustainable but also far more expensive than traditional beef. Why is that? Well plant-based chicken is more expensive because the processing infrastructure being used is more than 10 years behind real chicken processing, where you’ll see robot arms that cut up chicken so efficiently that it looks like a Tesla factory. [Alternative meat] companies are basically using these extruders built in the ’70s because the industry has been so small, and that’s because there’s been a lot of skepticism from the investment community in these companies. Or there was. The performance of Beyond Meat’s IPO ended it. Now there’s a rush of founders and dollars into that space, and whenever you have a space where the core infrastructure has been neglected, there’s opportunity. A former mechanical engineer with Boeing has started a company, Rebellyous Foods, to basically build the AWS for the plant-based food industry, for example. She’s using [the machines she’s building] to sell plant-based chicken nuggets, [but that’s the longer-term plan]. TC: Siraj, you say last year you started to spend time on energy. What’s interesting to you as it relates to energy? SK: There’s been some improvement in how we capture emissions, but [carbon emissions] are still very deleterious to our health and the planet’s health, and there are a few areas to think about [to address the problem]. Helping people measure and control their consumption is one approach, but also we think about how to produce new energy, which is a shift we [meaning mankind] need to undertake. The challenge [in making that shift] is often [capital expenditures]. It’s hard for venture investors to back companies that are [building nuclear reactors], which makes government grants the best choice for early innovation oftentimes. There is one company, Seaborg, that has figured out a clever reactor. It’s not a portfolio company but it’s [compelling]. SB: We also really like what Seaborg is doing. These [fourth generation] nuclear companies have a whole host of approaches that allow for smaller, safer reactors that you wouldn’t mind having in your backyard. But Siraj put his finger on it: as an early-stage deep tech investor, we have to consider the capital plan of a company, and if it needs to raise billions of dollars, early investors will get really diluted, so early-stage venture just isn’t the best fit. TC: There are other areas you like, though, because costs have fallen so much. SB: Yes. Satellite telephony used to be one of those areas. Some of the satellites in space right now cost $350 million [to launch] and took three to four years to build, which would be really hard for any early-stage investor to fund. But now, a new generation of companies is building satellites for one-tenth of the cost in months, not years. That’s a game changer. They can iterate faster. They can build a better product. They don’t have to raise equity to build and launch either; they can raise from a debt financier [from whom they can] borrow money and pay it back over time. That model isn’t available to a company like Uber or Lyft, because those companies can’t say, ‘X is going to cost us Y dollars and it will pay back Z over time.’ TC: What of concerns that all these cheap satellites are going to clog up the sky pretty quickly? SB: It’s a real concern. Most [of today’s satellites] are low earth satellites, and the closer to the earth they are, the brighter they are; they reflect the sun more, the more satellites we’re seeing instead of stars. I do think it’s incumbent on all of these companies to think about how they are contributing to the future of humanity. But when you connect the unconnected, educational outcomes improve, health improves, inequality decreases, and the stability of governments improves, so maybe the developed world needs to sacrifice a bit. I think that’s a reasonable tradeoff. If on the other hand, we’re putting up satellites to help people buy more crap . . . TC: It’s like the argument for self-driving cars in a way. Life becomes more efficient, but they’ll require far more energy generation, for example. There are always second-order consequences. SK: But think of how many people are killed in driving accidents, versus terrorist attacks. Humans have many great qualities, but being able to drive a lethal machine consistently isn’t one of them. So when we take that into perspective, it’s really important that we build autonomous vehicles. You [voice] a legitimate concern, and often when there are step changes, there are discontinuities along the way that lead to side effects that aren’t great. That comes down to several things. First, infrastructure will have to keep up. We’ll also have to create regulations that don’t lead to the worst outcomes. One our investments, Lilium in Munich, has built an entirely electric air taxi service that’s built on vertical takeoff. It’s nimble. It’s quiet enough to operate in city environments. On roads, cars are constrained by 2D terrain and buildings, but [in the air] if you can do dynamic air traffic control, it opens up far much efficient transport. If you can get from downtown London to Heathrow [airport] in five minutes versus 50 minutes in a Tesla? That’s far more energy efficient.

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/14/books/review/a-world-without-work-daniel-susskind.html
### Query Relevance Score: 0.16233661770820618
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times News subscription; current subscribers not eligible. Subscription excludes print edition. Subscription also excludes digital access to New York Times Games, Cooking, Wirecutter or The Athletic. Your payment method will automatically be charged in advance the introductory rate of $4 every 4 weeks for 1 year, and after 1 year the standard rate of $17 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.nytimes.com/2020/01/30/business/artificial-intelligence-robots-retail.html
### Query Relevance Score: 0.1515299677848816
### Highlights: None

The New York Times: Digital and Home Delivery Subscriptions Offer for a New York Times News subscription; current subscribers not eligible. Subscription excludes print edition. Subscription also excludes digital access to New York Times Games, Cooking, Wirecutter or The Athletic. Your payment method will automatically be charged in advance the introductory rate of $4 every 4 weeks for 1 year, and after 1 year the standard rate of $17 every 4 weeks. Your subscription will continue until you cancel. Cancellation takes effect at the end of your current billing period. Taxes may apply. Offer terms are subject to change. plus-icon check Subscribe to The Times to read (and print) as many articles as you’d like. nytimes.com/subscription

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war.print
### Query Relevance Score: 0.09863996505737305
### Highlights: None

By , Kris Osborn Published January 06, 2020 File photo - A 10th Mountain Division Soldier fires an M4 rifle during a platoon Situational Training Exercise at a range in Arta, Djibouti, Aug. 25, 2018. (U.S. Air Force photo by Senior Airman Haley D. Phillips) Targets emerge in seconds, incoming enemy fire puts lives at risk and shifting combat dynamics require immediate, on-the-spot decisions in a matter of seconds -- all as soldiers navigate the complex web of threats during all-out, high-risk ground-warfare. These kinds of predicaments, which characterize much of what soldiers train to face, are immeasurably improved by emerging applications of AI; artificial intelligence can already gather, fuse, organize and analyze otherwise disparate pools of combat-sensitive data for individual soldiers. Target information from night vision sensors, weapons sights, navigational devices and enemy fire detection systems can increasingly be gathered and organized for individual human soldier decision-makers. However, what comes after this? Where will AI go next in terms of changing modern warfare for Army infantry on the move in war? The Army Research Laboratory is now immersed in a complex new series of research and experimentation initiatives to explore a “next-level” of AI. Fundamentally, this means not only using advanced algorithms to ease the cognitive burden for individual soldiers -- but also network and integrate otherwise stovepiped applications of AI systems. In effect, this could be described as performing AI-enabled analytics on groups of AI systems themselves. “Autonomy is doing things in a snipped way that can be connected. We can benefit from an overarching AI approach, something that looks at the entire mission. Right now our autonomy solves very discreet problems that are getting more complicated,” J. Corde Lane, Ph.D., director, Human Research and Engineering, CCDC-Army Research Laboratory, told Warrior in an interview. F-35 SET FOR LASER BOOST What does this mean? In essence, it translates into a way combat commanders will not only receive AI-generated input from individual soldiers but also be able to assess how different AI systems can themselves be compared to one another and analyzed as a dynamic group. For instance, Lane explained, perhaps multiple soldier-centric AI-empowered assessments can be collected and analyzed in relation to one another with a mind to how they impact a broader, squad-level combat dynamic. In particular, simultaneous analysis of multiple soldier-oriented AI system can help determine the best course of action for an entire unit, in relation to an overall mission objective. “What is the entire mission and possible courses of action? Do we optimize the logistics flow? Find targets as the dynamic battlefield gets more complex? The Commander can draw upon advanced AI to explore new options,” Lane explained. Therefore, in addition to drawing upon algorithms able to organize data within a given individual system, future AI will encompass using real-time analytics to assess multiple systems simultaneously and how they impact one another to offer an overall integrated view. All of this progress, just as is the case now, will still rely heavily upon human decision-making faculties to optimize its added value for combat. Integrating a collective picture, drawing upon a greater range of variables will require soldiers to incorporate new tactics and methods of analysis to best leverage the additional available information. SOLDIERS USE AI TO FIRE PRECISION GRENADES, GUIDE DRONE ATTACKS “When we have new and improved autonomy coming in, soldiers need to know how to use that. How do you keep the soldier always at the center and adapt to them as you adapt to the new AI?” Lane asked. Perhaps one soldier receives organized sensor-driven targeting data relevant to a specific swath of terrain, while another AI system is organizing variables to determine the supply flow of ammunition, fuel or other logistical factors. “Data never seen cannot be learned. It is not about AI, but combining AI with a soldier who has the concept of an entire mission. AI provides information and then they get put together. When you are under fire, you are going to need different types of information,” Lane explained. For example, comparing and analyzing various AI systems to help engender a collective picture of some kind might enable a commander to know “if you go this way you will use more fuel but it will be safer,” as Lane explained. HOW AI CHANGES ATTACK MISSIONS FOR US FIGHTER JETS AND BOMBERS Interestingly, Lane’s point about the irreplaceable characteristics of human cognition in the face of new AI-driven technologies is anticipated in a 2017 essay from the Chatham House Royal Institute of International Affairs, called “Artificial Intelligence and the Future of War.” The essay, written by M.L. Cummings, states that “replicating the intangible concept of intuition, knowledge-based reasoning and true expertise is, for now, beyond the realm of computers.” Mathematically oriented computer algorithms naturally face limitations when it comes to things like judgments, feelings or quickly assessing not-yet-seen information; an AI-database can only be as effective as the information it already has stored in its database. While Machine-Learning techniques continue to accelerate the pace at which an existing AI database can quickly integrate and perform analytics on new information, AI-infused computing can only make decisions or solve problems in relation to the information it already has stored. Now it goes without saying that these databases are increasingly vast, almost seeming limitless, yet they do need to consistently be fed with not-yet-stored information of great relevance to wartime decisions. CLICK HERE TO GET THE FOX NEWS APP The Chatham House essay puts it this way: “Every autonomous system that interacts in a dynamic environment must construct a world model and continually update that model. This means that the world must be perceived (or sensed through cameras, microphones and/or tactile sensors) and then reconstructed in such a way that the computer ‘brain’ has an effective and updated model of the world it is in before it can make decisions. The fidelity of the world model and the timeliness of its updates are the keys to an effective autonomous system.” (Artificial Intelligence and the Future of War” M.L. Cummings) URL https://www.foxnews.com/tech/army-research-lab-pursues-new-next-generation-ai-for-soldiers-at-war

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/artificial-intelligence-satellite-images-exports-china-us-restrictions
### Query Relevance Score: 0.09713400155305862
### Highlights: None

Beginning Monday, technology companies in the U.S. will face new restrictions on exporting some of their more state-of-the-art products to China and elsewhere, according to the Commerce Department. These new export rules — for companies building artificial intelligence software for analyzing satellite imagery — are targeting emerging technology that could give the U.S. a significant military or intelligence advantage. A special license would be required to sell software outside the U.S. that could scan aerial images automatically to identify objects of interest, such as vehicles or houses. U.S. WILL DOUBLE EXPORTS TO CHINA UNDER 'PHASE ONE' DEAL: LIGHTHIZER The rules could affect a growing sector of the technology industry using algorithms to analyze satellite images of crops, trade patterns and other changes affecting the economy or environment. The new export rules are coming after Congress passed a law in 2018 that updated national security-related export controls to protect “emerging and foundational” technology that could end up in the hands of foreign governments. It’s an interim rule until the public has a chance to weigh in before March. Commerce Department officials said it’s in the national-security interests of the U.S. to implement the controls immediately Monday. CLICK HERE TO GET THE FOX NEWS APP The department didn’t return Fox News’ request for comment via email Sunday night. The Associated Press contributed to this report.

---

## Article published: 01/2020
### Source URL: https://www.foxnews.com/tech/google-just-created-the-most-detailed-image-of-a-brain-yet
### Query Relevance Score: 0.08808890730142593
### Highlights: None

Scientists created the most detailed map of a brain to date. This connectome depicts the neurons and synapses present in one-third of a fruit fly's brain. (Credit: FlyEM/Janelia Research Campus) Scientists have created the most detailed 3D map of an organism brain to date. The mesmerizing threads of blue, yellow, purple and green represent thousands of brain cells and millions of connections found inside the brain of a fruit fly. This high-resolution map, known as a "connectome," only makes up one-third of a fruit fly's brain but includes a large region involved in learning, navigation, smell and vision. Scientists found over 4,000 different types of neurons, including those involved in the fly's circadian rhythm — or internal clock — that might help researchers learn a bit more about how the insect sleeps, according to the publicly released data. This map, a collaboration between scientists at Google and the Janelia Research Campus in Virginia, took two years to create. The team started out by cutting a fruit fly brain into extremely thin slices using a hot knife — and then imaging each slice under an electron microscope. Afterward, they stitched the images together to create a large map, tracing the paths of the neurons through the brain, according to the statement. Related: 3D Images: Exploring the Human Brain The point of such maps is to reveal something about how specific physical connections in the brain are linked to distinct behaviors. But following each individual neuron in a journey across the brain is painstaking work — and critics note that such maps have not yet led to a major discovery, according to The Verge. The only organism to have its entire brain mapped this way is the roundworm C. elegans — a wriggly critter that only harbors around 300 to 400 neurons and around 7,000 synapses, or the junctions between brain cells. Other teams have attempted to map the human brain in lower resolution. But considering that the human brain contains 86 billion neurons, creating such a map will likely take some more time. The new map was published on Jan. 21 in the database BioRxiv, and it has not yet been peer reviewed. Inside the Brain: A Photo Journey Through Time Check Out These Amazing Super-Detailed Images of Fruit Fly Brains Dazzling Images of the Brain Created by Neuroscientist-Artist Originally published on Live Science.

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/ai-great-things-burn-planet/
### Query Relevance Score: 0.13694503903388977
### Highlights: None

Last month, researchers at OpenAI in San Francisco revealed an algorithm capable of learning, through trial and error, how to manipulate the pieces of a Rubik's Cube using a robotic hand. It was a remarkable research feat, but it required more than 1,000 desktop computers plus a dozen machines running specialized graphics chips crunching intensive calculations for several months. The effort may have consumed about 2.8 gigawatt-hours of electricity, estimates Evan Sparks, CEO of Determined AI, a startup that provides software to help companies manage AI projects. That’s roughly equal to the output of three nuclear power plants for an hour. A spokesperson for OpenAI questioned the calculation, noting that it makes several assumptions. But OpenAI declined to disclose further details of the project or offer an estimate of the electricity it consumed. Artificial intelligence routinely produces startling achievements, as computers learn to recognize images, converse, beat humans at sophisticated games, and drive vehicles. But all those advances require staggering amounts of computing power—and electricity—to devise and train algorithms. And as the damage caused by climate change becomes more apparent, AI experts are increasingly troubled by those energy demands. “The concern is that machine-learning algorithms in general are consuming more and more energy, using more data, training for longer and longer,” says Sasha Luccioni, a postdoctoral researcher at Mila, an AI research institute in Canada. It’s not just a worry for academics. As more companies across more industries begin to use AI, there’s growing fear that the technology will only deepen the climate crisis. Sparks says that Determined.ai is working with a pharmaceutical firm that’s already using huge AI models. “As an industry, it’s worth thinking about how we want to combat this,” he adds. Some AI researchers are thinking about it. They’re using tools to track the energy demands of their algorithms, or taking steps to offset their emissions. A growing number are touting the energy efficiency of their algorithms in research papers and at conferences. As the costs of AI rise, the AI industry is developing a new appetite for algorithms that burn fewer kilowatts. Luccioni recently helped launch a website that lets AI researchers roughly calculate the carbon footprint of their algorithms. She is also testing a more sophisticated approach—code that can be added to an AI program to track the energy use of individual computer chips. Luccioni and others are also trying to persuade companies that offer tools for tracking the performance of code to include some measure of energy or carbon footprint. “Hopefully this will go toward full transparency,” she says. “So that people will include in the footnotes ‘we emitted X tons of carbon, which we offset.’” The energy required to power cutting-edge AI has been on a steep upward curve for some time. Data published by OpenAI shows that the computing power required for key AI landmarks over the past few years, such as DeepMind’s Go-playing program AlphaZero, has doubled roughly every 3.4 months—increasing 300,000 times between 2012 and 2018. That’s faster than the rate at which computing power historically increased, the phenomenon known as Moore’s Law (named after Gordon Moore, cofounder of Intel.) Recent advances in natural language processing—an AI technique that helps machines parse, interpret, and generate text—have proven especially power-hungry. A research paper from a team at UMass Amherst found that training a single large NLP model may consume as much energy as a car over its entire lifetime—including the energy needed to build it. Training a powerful machine-learning algorithm often means running huge banks of computers for days, if not weeks. The fine-tuning required to perfect an algorithm, by for example searching through different neural network architectures to find the best one, can be especially computationally intensive. For all the hand-wringing, though, it remains difficult to measure how much energy AI actually consumes, and even harder to predict how much of a problem it could become. The Department of Energy estimates that data centers account for about 2 percent of total US electricity usage. Worldwide, data centers consume about 200 terawatt hours of power per year—more than some countries. And the forecast is for significant growth over the next decade, with some predicting that by 2030, computing and communications technology will consume between 8 percent and 20 percent of the world’s electricity, with data centers accounting for a third of that. In recent years, companies offering cloud computing services have sought to address spiraling power consumption and offset carbon emissions with varying measures of success. Google, for example, claims “zero net carbon emissions” for its data centers, thanks to extensive renewable energy purchases. Microsoft last week announced a plan to become “carbon negative” by 2030, meaning it would offset all of the carbon produced by the company over its history. OpenAI signed a deal to use Microsoft's cloud last July. It isn’t clear how the AI boom will fit with the bigger picture of data center energy use, or how it might alter it. Cloud providers do not disclose the overall energy demands of machine-learning systems. Microsoft, Amazon, and Google all declined to comment. Jonathan Koomey, a researcher and consultant who tracks data center energy use, cautions against drawing too many conclusions from cutting-edge AI demos. He notes that AI algorithms often run on specialized chips that are more efficient, so new chip architectures may offset some of the projected demand for compute power. He also says that the IT industry has in the past offset rising energy demands in one domain by lowering energy use in others. “People are likely to take isolated anecdotes and extrapolate to get eye popping numbers, and these numbers are almost always too high,” Koomey says. Still, as companies and other organizations increasingly use artificial intelligence, experts say it will become important to understand the technology’s energy footprint, both in data centers and in other devices and gadgets. “I would agree that the analysis community needs to get a handle on it,” says Eric Masanet, a professor at Northwestern University who leads its Energy and Resource Systems Analysis Laboratory. Some AI researchers aren’t waiting for the industry to wake up. Luccioni of Mila helped organize a workshop on climate change last month at an important AI conference, NeurIPS, and she was pleased to find that the event was standing room only. “There’s a lot of interest in this,” she says. The Allen Institute for AI, a research institute founded by the late Microsoft cofounder Paul Allen, has also called for greater awareness of AI’s environmental impact. The institute’s CEO, Oren Etzioni, says he is encouraged by the efforts of researchers, as many papers now include some account of the computational intensity of a particular algorithm or experiment. Etzioni adds that the industry as a whole is gradually waking up to energy efficiency. Even if this is largely because of the cost involved with training large AI models, it could help prevent AI from contributing to a looming climate catastrophe. “AI is clearly moving toward lighter models and greener AI,” he says. More Great WIRED Stories Chris Evans goes to Washington What Atlanta can teach tech about cultivating black talent The display of the future might be in your contact lens Here's what the world will look like in 2030 ... right? The war vet, the dating site, and the phone call from hell 👁 The case for a light hand with AI. Plus, the latest news on artificial intelligence 🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers, running gear (including shoes and socks), and best headphones

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/heres-what-the-world-will-look-like-in-2030-right/
### Query Relevance Score: 0.13056664168834686
### Highlights: None

Predicting the future is hard, but that doesn't stop people from trying—especially people named Elon Musk. As he well knows, being bold is pretty much the only way thought castles can become concrete (or wood, brick, or metal). In this list, WIRED has gathered a handful of far-reaching goals as a framework for what to expect in the decade ahead. Space colonies. A mega-expansion in genome sequencing. Sweet little nuclear power plants. It's never too early to start holding the promise-makers responsible for their claims. After all, even a bajillionaire needs an accountability buddy. Welcome to the Moon Base When the last person left the moon in 1972, few could have predicted that humans wouldn’t return for another 50 years. But NASA says this time around things will be different. The agency is planning a crewed mission to the moon in 2024, and this time it wants to stick around. The idea of the Artemis mission is to lay the foundation for a permanent human presence on and around the moon, which will then serve as a jump-off point for the agency’s journey to Mars. When Artemis was first announced, it was easy to be incredulous: The agency wants to use a rocket that hasn’t flown yet, it lacks the necessary funds for a moon mission ... the list goes on. But this year NASA has made big strides on the mission. The agency has selected a handful of companies to build components for its lunar gateway, a space station that will be in orbit around the moon, and it has solicited designs for a lunar lander. If NASA does hit its 2024 target for a crewed mission to the moon, it’s not so crazy to think it might have a permanent moon base by 2030. —Daniel Oberhaus Climate Apocalypse Now In October 2018 the UN warned that humanity has 12 years left to avoid catastrophic climate change. That means that by 2030, we’ll need to cut global greenhouse gas emissions in half, not so much a tall order as a towering one, given that emissions are still rising year to year. In fairness, the world won’t suddenly end on January 1, 2030, if we don’t meet that goal. But the report is spot-on in its mantra: The faster we switch to a world economy run on renewable energy, the better we can attenuate the consequences—stronger storms, rising seas, fiercer wildfires. So what can we do? For one, we need carbon taxes the world over: Release greenhouse gases and you pay a fee, which incentivizes the adoption of green energy. We have to massively subsidize solar panels and electric cars. We have to bolster public transportation and redesign cities to discourage the use of cars. And this may sound niche, but it’s hugely important: AC units need a fundamental redesign to be more efficient or even sequester CO2, as demand for them soars in lockstep with global temperatures. —Matt Simon Genomic Mega Millions If you think you’re currently living in the age of Big DNA, think again. The next decade will see a more than hundredfold boom in the world’s output of human genetic data. The drop in sequencing costs is shifting DNA testing out of the research lab and into mainstream medical practice. Population-based sequencing projects in more than a dozen countries, including the US, are expected to produce 60 million genomes by 2025. By 2030, China hopes to add another 100 million from its own precision medicine initiative. The impact is hard to even imagine. To date, only about a million people have had their whole genomes sequenced. And it’s not a very diverse cohort. More data from all over the globe will allow for more powerful, fine-grained analyses of how genes shape health and behavior. Very large genetic data sets are ideal for a new technique called Mendelian randomization, which mimics clinical trials, allowing researchers to tease apart causes and correlations. Bigger samples will also make it possible to forecast even complex traits—like height or susceptibility to heart disease—from DNA. A world so saturated with genetic data will come with its own risks. The emergence of genetic surveillance states and the end of genetic privacy loom. Technical advances in encrypting genomes may help ameliorate some of those threats. But new laws will need to keep the risks and benefits of so much genetic knowledge in balance. —Megan Molteni Teeny Tiny Nuclear Power Plants By 2030, the Vogtle power plant in Georgia, the only nuclear power station currently under construction in the US, will have been running for a few years. It's likely to be the decade's only new large-scale nuclear power plant to come online, but that doesn’t mean the United States is abandoning fission energy. Instead, expect to see small nuclear reactors start popping up. Just a fraction of the size of a typical nuclear reactor, these advanced ones can be mass-produced and easily shipped anywhere in the country, no matter how remote. The first small reactors, developed by a company called NuScale Power, should start splitting atoms at Idaho National Laboratories in 2026. The Department of Energy is also working to get even smaller reactors, known as microreactors, churning out electrons at a federal facility by 2027. Nuclear energy gets a bad rap in some American environmental circles and it’s not hard to see why. The meltdown at Three Mile Island and the decades-long debate about storing nuclear waste at Yucca Mountain have made people skittish about the prospects of this carbon-free energy source, but the UN and many experts say fission energy will be key to hitting our climate goals. The world needs to halve its carbon emissions by 2030, and embracing the new generation of nuclear reactors may be key to making that happen. —Daniel Oberhaus Elon Musk's Plan for Mars Sending life to Mars has been Elon Musk’s goal from day one, and this is the decade he has pegged for his touchdown on the red planet. Originally, he wanted to ship off some plants in a greenhouse, but as SpaceX came to dominate the new space industry, Musk’s ambitions have risen in tandem to include a full-fledged Mars colony. In 2019 he showed off, for the first time, the rocket that could make that happen. Musk’s Mars timeline is predictably slippery. In 2017 he predicted SpaceX would send a cargo mission to Mars by 2022. The following year, he said the first crewed mission to Mars would happen in seven to ten years, or no later than 2028. Musk is notorious for wildly underestimating the amount of time it takes to accomplish his ambitious goals, so don't schedule your launch parties just yet. Still, he tends to follow through on his promises—eventually. —Daniel Oberhaus Goodbye, Poverty! Predictions for the future often have a sci-fi bent: jet packs, flying cars, brain-computer hybrids. The United Nations is supposed to stick to more solid ground, but some of its Sustainable Development Goals for 2030 sound nearly as fantastical. In a mere 10 years, the UN plans to eradicate poverty “in all its forms everywhere.” No big deal. The UN already declared October 17 International Poverty Eradication Day. But elevating the lives of those subsisting on less than $1.25 a day will take a little more. The good news is that crushing global poverty has declined significantly: The World Bank reports that 1.1 billion fewer people live in extreme poverty than did in 1990. The organization has been working with countries to improve education, gender equality, food security, social services, and more. But the gains are unevenly distributed, and climate change now threatens to undo much of the progress, pushing millions back into destitution and creating a “climate apartheid.” This is already happening in Central America and Africa, where drought has caused millions to leave their homes. The prospect of ending poverty seems, well, poor. But let's face it, the future is unknowable. The 1900 edition of Ladies’ Home Journal predicted that, within the century, pneumatic tubes would deliver goods to homes and the letters C, X, and Q would drop out of the alphabet. Yet it also foresaw the mobile phone and color photography. Strong science coupled with political will might yet turn climate change around, and transform the UN’s predictions from a dream into reality. —Sara Harrison More Great WIRED Stories Instagram, my daughter, and me Tweak these Google Chrome settings to level up your browsing Welcome to Rachel, Nevada—the town closest to Area 51 The Irishman gets de-aging right—no tracking dots necessary Ewoks are the most tactically advanced fighting force in Star Wars 👁 Will AI as a field "hit the wall" soon? Plus, the latest news on artificial intelligence 🎧 Things not sounding right? Check out our favorite wireless headphones, soundbars, and Bluetooth speakers

---

## Article published: 01/2020
### Source URL: https://www.wired.com/story/live-your-best-digital-life-2020/
### Query Relevance Score: 0.11624865233898163
### Highlights: None

Years of mounting uneasiness around smartphones and the internet have established a new genre on the bookshelf: the technology self-help book. Last decade began with diagnoses of our troubled minds, in tomes like Nicholas Carr’s The Shallows: What the Internet Is Doing to Our Brains , published in 2010. More recently, the genre has shifted toward solutions. A whole shelf’s worth of books dedicated to directly addressing this techno-discontentment came out in 2019, with titles like Indistractable: How to Control Your Attention and Choose Your Life (by Nir Eyal), Digital Minimalism: Choosing a Focused Life in a Noisy World (by Cal Newport), and How to Do Nothing: Resisting the Attention Economy (by Jenny Odell). Undergirding this genre is an implicit dialectic: Technology has changed us, robbed us of something important, and we must get it back. It’s your devices versus your best life. Just in time for a new decade, though, several fresh books offer a more measured approach to living in the age of technology. These are not self-help books, or even books that confront our relationship with technology head-on. Instead, they examine the realities of a tech-saturated world and offer a few simple ideas for rewriting bad habits, reviewing the devices we actually need, and relearning how to listen amid all the noise. Few people claim more authority on the topic of coexisting with tech than B. J. Fogg, whose new book, Tiny Habits , was published December 31. The founder of Stanford University’s Behavior Design Lab, Fogg has spent more than a decade studying the architecture of human behavior. He’s interested in the little nudges that change the way people make decisions, and his work has been used by the tech industry to develop habit-forming products. His first book, from 2003, focused on Persuasive Technology: Using Computers to Change What We Think and Do , and his classroom has educated the likes of Ed Baker, who would go on to lead growth at Facebook and Uber, and Kevin Systrom and Mike Krieger, the founders of Instagram. In Tiny Habits, Fogg neatly translates a decade of research into a three-step program: Find a behavior you want to adopt (reading the newspaper rather than Twitter), tack it onto an existing routine (drinking a cup of coffee every morning) and then celebrate, liberally, every time it’s done (self-congratulation works). The last step is not to be skipped; celebration is to Foggianism as zen is to Buddhism. He suggests starting with microscopic behaviors (just read one headline in the newspaper every morning after you drink your cup of coffee) to encourage better adoption. A similar program works for undoing bad habits. Fogg’s method is meant to work for any habit—not just escaping the Instagram scroll, but remembering to floss your teeth, developing an exercise routine, or practicing the guitar. That’s because all human behavior, according to Fogg, follows the same basic formula: We form a habit to do something when we are motivated, able, and are prompted to do so. (The design of apps like Instagram, a careful reader will note, also follow this basic formula.) The book begins with an overview of this basic idea (replete with graphics and charts) and then spends a chapter explaining each variable. Tiny Habits isn't about how technology itself has derailed our good choices, though it’s sprinkled liberally with complaints of bad tech hygiene: a student who scrolls through Facebook every morning rather than getting up to exercise, the husband who can’t put his phone down during dinner. But Fogg is far from a tech teetotaler. He also offers examples of how posting about new habits can hold people accountable, and how social technology can help people change their behaviors together, for good. If Fogg’s approach to health tech habits is a matter of searching within, the writer Kyle Chayka suggests looking at the stuff around you. His forthcoming book, The Longing for Less (out January 21), chronicles the rise of minimalism. Chayka, who has written about the ways algorithms flatten our personal taste and the homogeneity of the Silicon Valley aesthetic, seems suspicious about whether technology’s influence has been mostly good or bad. His curiosity about minimalism, then, reads like a response to a time when everyone is bombarded with digital information, superfluous gadgets, and online advertising designed to compel instantaneous purchases. Given all the digital detritus, it makes sense that some people are longing for some empty space. But this isn’t really a book about technology, and Chayka offers a more careful consideration of the movement’s origins. The Longing for Less tries to understand the current obsession with minimalism in all its complexity: the influence of Silicon Valley, yes, but also capitalism, the economy in the early 2000s, Stoic philosophy, Marie Kondo. Over four chapters—”Reduction,” “Emptiness,” “Silence,” and “Shadow”—Chayka takes the reader through history and around the world, giving equal consideration to minimalists like Steve Jobs (who lived in a giant house that remained entirely empty) as he does to Cicero. It would be a mistake to take The Longing for Less as a work of pragmatic advice. It doesn't make a compelling argument either for or against minimalism in practice. As for technology, Chayka includes a few anecdotes about taming it in his own life: Throughout the book, he mentions experiences turning off his Wi-Fi, visiting a sensory-deprivation tank, and spending $700 on a retreat in rural Sweden where he is forced to surrender all devices for a week. By the end of the book, he doesn’t seem to find nirvana in all the silence—but he gives readers a few reasons to hold off on buying that new iPhone.

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/31/report-ai-algorithm-sent-first-warnings-about-chinas-coronavirus/
### Query Relevance Score: 0.08706717938184738
### Highlights: None

According to a recent report by Wired, a Canadian AI-driven algorithm called BlueDot sent the first warnings of the coronavirus outbreak in China beating both the CDC and the WHO. Wired reports that on January 6, the CDC issued a warning about a possible virus outbreak in China, the WHO made a similar announcement on January 9 after a number of pneumonia cases were reported in Wuhan. But both were beaten to the report by a Canadian AI health monitoring platform called BlueDot which sent warnings to customers on December 31, 2019. BlueDot uses an AI-driven algorithm to search through foreign-language news reports, animal and plant disease networks, and official statements from government bodies in order to warn its clients of danger zones such as Wuhan which has become the center of the coronavirus outbreak in China. Public health officials at the WHO and CDC are forced to rely on reports from Chinese officials — who are often not very forthcoming with information — but BlueDot relies on artificial intelligence that may prove faster than official statements. Kamran Khan, BlueDot’s founder and CEO, commented on the algorithm stating: “We know that governments may not be relied upon to provide information in a timely fashion. We can pick up news of possible outbreaks, little murmurs or forums or blogs of indications of some kind of unusual events going on.” Khan worked as a hospital infectious disease specialist in Toronto during the SARS epidemic of 2003 and commented on the current coronavirus situation stating: “There’s a bit of deja vu right now. In 2003, I watched the virus overwhelm the city and cripple the hospital. There was an enormous amount of mental and physical fatigue, and I thought, ‘Let’s not do this again.’” Khan launched BlueDot in 2014 and raised $9.4 million in venture capital funding, the firm now employees 40 people including physicians and programmers who have worked to develop the disease surveillance analytic program that uses natural language processing and machine learning techniques to sort through news reports in 65 languages as well as airline data and animal disease outbreak reports. “What we have done is use natural language processing and machine learning to train this engine to recognize whether this is an outbreak of anthrax in Mongolia versus a reunion of the heavy metal band Anthrax,” Kahn says. Read more about BlueDot at Wired here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/27/mit-technology-review-amazons-alexa-devices-are-recording-your-life/
### Query Relevance Score: 0.08384797722101212
### Highlights: None

AP Photo/Charles Krupa The MIT Technology Review reported in 2018 that Amazon Alexa home assistant devices may actually be listening in on people’s daily lives even when not given commands. Despite such warnings, the e-commerce giant sold out of Alexa-powered devices before Christmas as their popularity continues to grow unabated. The MIT Technology Review reported in an article titled “Yes, Alexa is recording mundane details of your life, and it’s creepy as hell,” that Amazon Alexa home assistant devices are listening in on people’s conversations, a theory that has been around for some time but has never been confirmed. The MIT Technology Review reports: Beyond all the things I’ve clearly asked Alexa to do, in the past several months it has also tuned in, frequently several times a day, for no obvious reason. It’s heard me complain to my dad about something work-related, chide my toddler about eating dinner, and talk to my husband—the kinds of normal, everyday things you say at home when you think no one else is listening. And that’s precisely why it’s terrifying: this sort of mundane chitchat is my mundane chitchat. I invited Alexa into our living room to make it easier to listen to Pandora and occasionally check the weather, not to keep a log of intimate family details or record my kid saying “Mommy, we going car” and forward it to Amazon’s cloud storage. The MIT Technology Review notes that constant recording is one of the unfortunate downsides of home assistants that constantly listen for wake words such as “Alexa!” or “Hey, Siri!” Through 2019, Amazon faced continual bad news about its Alexa-powered devices on the subject of user privacy and security. Reports were published showing that Amazon employees and contractors located in India, Costa Rica, and Romania had ready access to users’ recordings and spent nine hours a day listening to the snippets. The work is mostly mundane. One worker in Boston said he mined accumulated voice data for specific utterances such as “Taylor Swift” and annotated them to indicate the searcher meant the musical artist. Occasionally the listeners pick up things Echo owners likely would rather stay private: a woman singing badly off key in the shower, say, or a child screaming for help. The teams use internal chat rooms to share files when they need help parsing a muddled word—or come across an amusing recording. This revelation led to a lawsuit against Amazon which claimed that Jeff Bezos’ Big Tech giant was breaking the law by recording children without their parent’s consent. In another threat to security, researchers in Tokyo documented that Amazon’s voice assistant hardware could be hacked with a $5 laser pointer. Despite the negativity about Amazon’s devices recording users when they don’t expect it, sales of Alexa-powered devices have continued to rise. Early in 2019, Amazon announced that it had sold 100 million Alexa devices. Sales haven’t slowed down since then. Although the company has not released Christmas sales figures, for the third quarter of 2019, it sold more than 10 million devices and enjoys a 36 percent share of the market. It’s next closest competitor, the Chinese company Alibaba, has a 13 percent market share. Breitbart News has previously published a guide explaining how to stop Amazon employees from having access to Alexa recordings, however, this does not stop the device from recording users’ daily interactions but rather protects them from being listened to by Amazon employees directly. Read the full guide here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---

## Article published: 01/2020
### Source URL: https://www.breitbart.com/tech/2020/01/20/nyt-facial-recognition-startup-threatens-privacy-as-we-know-it/
### Query Relevance Score: 0.07159510999917984
### Highlights: None

The New York Times published an investigation recently into a little-known startup that helps law enforcement match photos of unknown people to their online images using facial recognition, and the privacy issues that are raised by the company and its massive database of photos. The New York Times writes in an article titled “The Secretive Company That Might End Privacy as We Know It” that a new tech startup that has been working with law enforcement could raise serious privacy issues for members of the public. Clearview AI, a facial recognition tech startup, has developed a system that allows users to upload a photo of a person to the app and see public photos of that person, along with links to where those photos appeared. The system scrapes information from Facebook, YouTube, Venmo and millions of other websites to help law enforcement track down individuals. The New York Times writes: Federal and state law enforcement officers said that while they had only limited knowledge of how Clearview works and who is behind it, they had used its app to help solve shoplifting, identity theft, credit card fraud, murder and child sexual exploitation cases. Until now, technology that readily identifies everyone based on his or her face has been taboo because of its radical erosion of privacy. Tech companies capable of releasing such a tool have refrained from doing so; in 2011, Google’s chairman at the time said it was the one technology the company had held back because it could be used “in a very bad way.” Some large cities, including San Francisco, have barred police from using facial recognition technology. The technology is reportedly being used by multiple law enforcement agencies amongst other groups, but many security experts have warned that the technology could easily be weaponized: “The weaponization possibilities of this are endless,” said Eric Goldman, co-director of the High Tech Law Institute at Santa Clara University. “Imagine a rogue law enforcement officer who wants to stalk potential romantic partners, or a foreign government using this to dig up secrets about people to blackmail them or throw them in jail.” The New York Times also notes that while investigating Clearview and finding little accurate public information about the company, Clearview began to investigate the Times reporter looking into the company: While the company was dodging me, it was also monitoring me. At my request, a number of police officers had run my photo through the Clearview app. They soon received phone calls from company representatives asking if they were talking to the media — a sign that Clearview has the ability and, in this case, the appetite to monitor whom law enforcement is searching for. Facial recognition technology has always been controversial. It makes people nervous about Big Brother. It has a tendency to deliver false matches for certain groups, like people of color. And some facial recognition products used by the police — including Clearview’s — haven’t been vetted by independent experts. Read more about Clearview and facial recognition technology at the New York Times here. Lucas Nolan is a reporter for Breitbart News covering issues of free speech and online censorship. Follow him on Twitter @LucasNolan or email him at lnolan@breitbart.com

---
